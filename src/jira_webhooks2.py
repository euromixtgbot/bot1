import json
import logging
import asyncio
import traceback
from typing import Dict, Any, Optional, List, Tuple
import re
import urllib.parse
import time
from collections import defaultdict
from io import BytesIO

import httpx
import requests
from aiohttp import web
import sys
import os

# Add the parent directory to the path to find config
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)

from config.config import (
    JIRA_DOMAIN, JIRA_API_TOKEN, JIRA_EMAIL, JIRA_REPORTER_ACCOUNT_ID, TELEGRAM_TOKEN,
    WEBHOOK_RATE_LIMIT_ENABLED, WEBHOOK_RATE_LIMIT_MAX_REQUESTS, WEBHOOK_RATE_LIMIT_WINDOW,
    WEBHOOK_RATE_LIMIT_BLACKLIST_DURATION, WEBHOOK_IP_WHITELIST_ENABLED, WEBHOOK_IP_WHITELIST_CUSTOM
)
from src.services import find_user_by_jira_issue_key
from src.fixed_issue_formatter import format_issue_info, format_issue_text
from src.jira_attachment_utils import build_attachment_urls, download_file_from_jira, normalize_jira_domain
from src.attachment_processor import process_attachments_for_issue

# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î–º–æ –ª–æ–≥—É–≤–∞–Ω–Ω—è –∑ —Ä–æ—Ç–∞—Ü—ñ—î—é –¥–ª—è –≤–µ–±—Ö—É–∫—ñ–≤
from logging.handlers import RotatingFileHandler
from datetime import datetime

# –°—Ç–≤–æ—Ä—é—î–º–æ –æ–∫—Ä–µ–º–∏–π –ª–æ–≥–µ—Ä –¥–ª—è –≤–µ–±—Ö—É–∫—ñ–≤ –∑ —Ä–æ—Ç–∞—Ü—ñ—î—é
webhook_log_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
webhook_log_filename = f'logs/webhook_001_{webhook_log_timestamp}.log'

# –ù–∞–ª–∞—à—Ç–æ–≤—É—î–º–æ —Ä–æ—Ç—É—é—á–∏–π —Ñ–∞–π–ª–æ–≤–∏–π —Ö–µ–Ω–¥–ª–µ—Ä –¥–ª—è –≤–µ–±—Ö—É–∫—ñ–≤ (5MB –º–∞–∫—Å–∏–º—É–º, 10 —Ñ–∞–π–ª—ñ–≤)
webhook_rotating_handler = RotatingFileHandler(
    webhook_log_filename,
    maxBytes=5*1024*1024,  # 5MB
    backupCount=10,        # –ó–±–µ—Ä—ñ–≥–∞—Ç–∏ –¥–æ 10 —Ñ–∞–π–ª—ñ–≤
    encoding='utf-8'
)

# –ù–∞–ª–∞—à—Ç–æ–≤—É—î–º–æ —Ñ–æ—Ä–º–∞—Ç—É–≤–∞–Ω–Ω—è –¥–ª—è –≤–µ–±—Ö—É–∫ –ª–æ–≥—ñ–≤
webhook_formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
webhook_rotating_handler.setFormatter(webhook_formatter)

# –°—Ç–≤–æ—Ä—é—î–º–æ logger –¥–ª—è –≤–µ–±—Ö—É–∫—ñ–≤
logger = logging.getLogger(__name__)
logger.addHandler(webhook_rotating_handler)
logger.setLevel(logging.INFO)

# === –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏ ===
# –¢–∏–ø–∏ –ø–æ–¥—ñ–π, –Ω–∞ —è–∫—ñ —Ä–µ–∞–≥—É—î–º–æ
EVENT_ISSUE_UPDATED = "jira:issue_updated"
EVENT_COMMENT_CREATED = "comment_created"
EVENT_ISSUE_CREATED = "jira:issue_created"
EVENT_ATTACHMENT_CREATED = "attachment_created"

# === SECURITY: Rate Limiting and IP Whitelist ===
# Rate limiting: –º–∞–∫—Å–∏–º—É–º –∑–∞–ø–∏—Ç—ñ–≤ –∑ –æ–¥–Ω–æ–≥–æ IP –∑–∞ –≤—ñ–∫–Ω–æ —á–∞—Å—É
RATE_LIMIT_WINDOW = WEBHOOK_RATE_LIMIT_WINDOW  # —Å–µ–∫—É–Ω–¥ (–∑ config)
RATE_LIMIT_MAX_REQUESTS = WEBHOOK_RATE_LIMIT_MAX_REQUESTS  # –º–∞–∫—Å–∏–º—É–º –∑–∞–ø–∏—Ç—ñ–≤ –∑–∞ –≤—ñ–∫–Ω–æ (–∑ config)
RATE_LIMIT_BLACKLIST_DURATION = WEBHOOK_RATE_LIMIT_BLACKLIST_DURATION  # —Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—å –±–ª–æ–∫—É–≤–∞–Ω–Ω—è (–∑ config)

# IP Whitelist: –¥–æ–∑–≤–æ–ª–µ–Ω—ñ IP-–∞–¥—Ä–µ—Å–∏ –¥–ª—è webhook –∑–∞–ø–∏—Ç—ñ–≤
# Jira Cloud IP ranges (–æ–Ω–æ–≤–ª–µ–Ω–æ —Å—Ç–∞–Ω–æ–º –Ω–∞ 2025)
IP_WHITELIST = {
    # Localhost –¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è
    "127.0.0.1",
    "::1",
    
    # Jira Cloud IP ranges (Atlassian)
    # https://support.atlassian.com/organization-administration/docs/ip-addresses-and-domains-for-atlassian-cloud-products/
    "13.52.5.0/24",
    "13.236.8.0/21",
    "18.136.0.0/16",
    "18.184.0.0/16",
    "18.234.32.0/20",
    "18.246.0.0/16",
    "52.215.192.0/21",
    "104.192.136.0/21",
    "185.166.140.0/22",
    "185.166.142.0/23",
    "185.166.143.0/24",
    
    # –í–Ω—É—Ç—Ä—ñ—à–Ω—è –º–µ—Ä–µ–∂–∞ (—è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ)
    "192.168.0.0/16",
    "10.0.0.0/8",
}

# –î–æ–¥–∞—î–º–æ custom IP –∑ config
if WEBHOOK_IP_WHITELIST_CUSTOM:
    for ip in WEBHOOK_IP_WHITELIST_CUSTOM.split(','):
        ip = ip.strip()
        if ip:
            IP_WHITELIST.add(ip)
            logger.info(f"‚úÖ Added custom IP to whitelist from config: {ip}")

# –ì–ª–æ–±–∞–ª—å–Ω—ñ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ –¥–ª—è rate limiting
from collections import deque
RATE_LIMIT_TRACKER: Dict[str, deque] = defaultdict(lambda: deque(maxlen=RATE_LIMIT_MAX_REQUESTS))
RATE_LIMIT_BLACKLIST: Dict[str, float] = {}  # {ip: blacklist_until_timestamp}

def is_ip_in_whitelist(ip: str) -> bool:
    """
    –ü–µ—Ä–µ–≤—ñ—Ä—è—î —á–∏ IP-–∞–¥—Ä–µ—Å–∞ –≤ whitelist (–≤–∫–ª—é—á–∞—é—á–∏ –ø—ñ–¥–º–µ—Ä–µ–∂—ñ CIDR).
    
    Args:
        ip: IP-–∞–¥—Ä–µ—Å–∞ –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏
        
    Returns:
        bool: True —è–∫—â–æ IP –¥–æ–∑–≤–æ–ª–µ–Ω–∏–π
    """
    from ipaddress import ip_address, ip_network
    
    try:
        ip_obj = ip_address(ip)
        for allowed in IP_WHITELIST:
            if '/' in allowed:
                # CIDR notation
                if ip_obj in ip_network(allowed, strict=False):
                    return True
            else:
                # Exact IP match
                if str(ip_obj) == allowed:
                    return True
        return False
    except ValueError:
        logger.warning(f"Invalid IP address format: {ip}")
        return False

def check_rate_limit(ip: str) -> Tuple[bool, str]:
    """
    –ü–µ—Ä–µ–≤—ñ—Ä—è—î rate limit –¥–ª—è IP-–∞–¥—Ä–µ—Å–∏.
    
    Args:
        ip: IP-–∞–¥—Ä–µ—Å–∞ –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏
        
    Returns:
        Tuple[bool, str]: (–¥–æ–∑–≤–æ–ª–µ–Ω–∏–π, –ø—Ä–∏—á–∏–Ω–∞ –±–ª–æ–∫—É–≤–∞–Ω–Ω—è)
    """
    current_time = time.time()
    
    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —á–∏ IP –≤ —á–æ—Ä–Ω–æ–º—É —Å–ø–∏—Å–∫—É
    if ip in RATE_LIMIT_BLACKLIST:
        blacklist_until = RATE_LIMIT_BLACKLIST[ip]
        if current_time < blacklist_until:
            remaining = int(blacklist_until - current_time)
            return False, f"IP blacklisted for {remaining}s (rate limit exceeded)"
        else:
            # –ß–∞—Å –±–ª–æ–∫—É–≤–∞–Ω–Ω—è –∑–∞–∫—ñ–Ω—á–∏–≤—Å—è
            del RATE_LIMIT_BLACKLIST[ip]
            RATE_LIMIT_TRACKER[ip].clear()
    
    # –û—Ç—Ä–∏–º—É—î–º–æ —ñ—Å—Ç–æ—Ä—ñ—é –∑–∞–ø–∏—Ç—ñ–≤ –¥–ª—è —Ü—å–æ–≥–æ IP
    request_times = RATE_LIMIT_TRACKER[ip]
    
    # –í–∏–¥–∞–ª—è—î–º–æ —Å—Ç–∞—Ä—ñ –∑–∞–ø–∏—Ç–∏ (–ø–æ–∑–∞ –≤—ñ–∫–Ω–æ–º)
    while request_times and request_times[0] < current_time - RATE_LIMIT_WINDOW:
        request_times.popleft()
    
    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –ª—ñ–º—ñ—Ç
    if len(request_times) >= RATE_LIMIT_MAX_REQUESTS:
        # –ü–µ—Ä–µ–≤–∏—â–µ–Ω–æ –ª—ñ–º—ñ—Ç - –¥–æ–¥–∞—î–º–æ –≤ —á–æ—Ä–Ω–∏–π —Å–ø–∏—Å–æ–∫
        RATE_LIMIT_BLACKLIST[ip] = current_time + RATE_LIMIT_BLACKLIST_DURATION
        logger.warning(f"üö´ Rate limit exceeded for IP {ip}: {len(request_times)} requests in {RATE_LIMIT_WINDOW}s. Blacklisted for {RATE_LIMIT_BLACKLIST_DURATION}s")
        return False, f"Rate limit exceeded: {len(request_times)}/{RATE_LIMIT_MAX_REQUESTS} requests per {RATE_LIMIT_WINDOW}s"
    
    # –î–æ–¥–∞—î–º–æ –ø–æ—Ç–æ—á–Ω–∏–π –∑–∞–ø–∏—Ç
    request_times.append(current_time)
    return True, ""

@web.middleware
async def security_middleware(request: web.Request, handler) -> web.Response:
    """
    Middleware –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ –±–µ–∑–ø–µ–∫–∏ –∑–∞–ø–∏—Ç—ñ–≤ (IP whitelist, rate limiting).
    
    Args:
        request: –í—Ö—ñ–¥–Ω–∏–π –∑–∞–ø–∏—Ç
        handler: –ù–∞—Å—Ç—É–ø–Ω–∏–π –æ–±—Ä–æ–±–Ω–∏–∫
        
    Returns:
        web.Response: –í—ñ–¥–ø–æ–≤—ñ–¥—å
    """
    # –û—Ç—Ä–∏–º—É—î–º–æ IP-–∞–¥—Ä–µ—Å—É –∫–ª—ñ—î–Ω—Ç–∞
    # –í—Ä–∞—Ö–æ–≤—É—î–º–æ proxy (X-Forwarded-For, X-Real-IP)
    client_ip = request.headers.get('X-Forwarded-For', '').split(',')[0].strip()
    if not client_ip:
        client_ip = request.headers.get('X-Real-IP', '').strip()
    if not client_ip:
        client_ip = request.remote or '0.0.0.0'
    
    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ 1: IP Whitelist (—è–∫—â–æ —É–≤—ñ–º–∫–Ω–µ–Ω–∞)
    if WEBHOOK_IP_WHITELIST_ENABLED:
        if not is_ip_in_whitelist(client_ip):
            logger.warning(f"üö´ Blocked request from non-whitelisted IP: {client_ip} (path: {request.path})")
            return web.json_response(
                {"status": "error", "message": "Access denied"},
                status=403
            )
    
    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ 2: Rate Limiting (—è–∫—â–æ —É–≤—ñ–º–∫–Ω–µ–Ω–∞)
    if WEBHOOK_RATE_LIMIT_ENABLED:
        allowed, reason = check_rate_limit(client_ip)
        if not allowed:
            logger.warning(f"üö´ Blocked request from {client_ip}: {reason}")
            return web.json_response(
                {"status": "error", "message": "Too many requests"},
                status=429
            )
    
    # –ó–∞–ø–∏—Ç –¥–æ–∑–≤–æ–ª–µ–Ω–∏–π
    return await handler(request)

def add_ip_to_whitelist(ip: str) -> bool:
    """
    –î–æ–¥–∞—î IP-–∞–¥—Ä–µ—Å—É –¥–æ whitelist (–¥–ª—è –∞–¥–º—ñ–Ω—ñ—Å—Ç—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è).
    
    Args:
        ip: IP-–∞–¥—Ä–µ—Å–∞ –∞–±–æ CIDR –ø—ñ–¥–º–µ—Ä–µ–∂–∞
        
    Returns:
        bool: True —è–∫—â–æ —É—Å–ø—ñ—à–Ω–æ –¥–æ–¥–∞–Ω–æ
    """
    try:
        from ipaddress import ip_address, ip_network
        
        # –í–∞–ª—ñ–¥–∞—Ü—ñ—è
        if '/' in ip:
            ip_network(ip, strict=False)  # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ CIDR
        else:
            ip_address(ip)  # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ IP
        
        IP_WHITELIST.add(ip)
        logger.info(f"‚úÖ Added IP to whitelist: {ip}")
        return True
    except ValueError as e:
        logger.error(f"‚ùå Invalid IP format: {ip} - {e}")
        return False

def remove_ip_from_blacklist(ip: str) -> bool:
    """
    –í–∏–¥–∞–ª—è—î IP-–∞–¥—Ä–µ—Å—É –∑ blacklist (–¥–ª—è –∞–¥–º—ñ–Ω—ñ—Å—Ç—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è).
    
    Args:
        ip: IP-–∞–¥—Ä–µ—Å–∞
        
    Returns:
        bool: True —è–∫—â–æ —É—Å–ø—ñ—à–Ω–æ –≤–∏–¥–∞–ª–µ–Ω–æ
    """
    if ip in RATE_LIMIT_BLACKLIST:
        del RATE_LIMIT_BLACKLIST[ip]
        if ip in RATE_LIMIT_TRACKER:
            RATE_LIMIT_TRACKER[ip].clear()
        logger.info(f"‚úÖ Removed IP from blacklist: {ip}")
        return True
    else:
        logger.warning(f"‚ö†Ô∏è IP not in blacklist: {ip}")
        return False

# –¢–∏–ø–∏ –ø–æ–¥—ñ–π, —è–∫—ñ –º–∏ –ª–æ–≥—É—î–º–æ –∞–ª–µ –Ω–µ –æ–±—Ä–æ–±–ª—è—î–º–æ
EVENT_ISSUE_PROPERTY_SET = "issue_property_set"
EVENT_ISSUELINK_CREATED = "issuelink_created"
EVENT_WORKLOG_CREATED = "worklog_created"
EVENT_WORKLOG_UPDATED = "worklog_updated"
EVENT_WORKLOG_DELETED = "worklog_deleted"
EVENT_USER_CREATED = "user_created"
EVENT_USER_UPDATED = "user_updated"

# –ö–µ—à –¥–ª—è –∑–±–µ—Ä—ñ–≥–∞–Ω–Ω—è –≤—ñ–¥–ø—Ä–∞–≤–ª–µ–Ω–∏—Ö –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å, —â–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ –¥—É–±–ª—ñ–∫–∞—Ç—ñ–≤
# –°—Ç—Ä—É–∫—Ç—É—Ä–∞: {issue_key: [{"text": "message_text", "time": timestamp}]]}
# –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ç—ñ–ª—å–∫–∏ –æ—Å—Ç–∞–Ω–Ω—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∑–∞ –æ—Å—Ç–∞–Ω–Ω—ñ 5 —Ö–≤–∏–ª–∏–Ω
RECENT_MESSAGES_CACHE: Dict[str, List[Dict[str, Any]]] = defaultdict(list)
CACHE_TTL = 300  # 5 minutes

# ===== ATTACHMENT CACHING SYSTEM =====
# –ö–µ—à –¥–ª—è –∑–±–µ—Ä—ñ–≥–∞–Ω–Ω—è –ø–æ–¥—ñ–π attachment_created –¥–æ –ø—Ä–∏–±—É—Ç—Ç—è comment_created
# –°—Ç—Ä—É–∫—Ç—É—Ä–∞: {issue_key: [{"attachment": attachment_data, "timestamp": time, "filename": str}]}
PENDING_ATTACHMENTS_CACHE: Dict[str, List[Dict[str, Any]]] = defaultdict(list)
ATTACHMENT_CACHE_TTL = 300  # 5 minutes - INCREASED for debugging timing issues

# –ù–û–í–ò–ô –ì–õ–û–ë–ê–õ–¨–ù–ò–ô –ö–ï–® –ó–ê ATTACHMENT_ID (–¥–ª—è –≤–∫–ª–∞–¥–µ–Ω—å –±–µ–∑ issue_key)
# –°—Ç—Ä—É–∫—Ç—É—Ä–∞: {attachment_id: {"attachment": data, "timestamp": time, "filename": str}}
ATTACHMENT_ID_CACHE: Dict[str, Dict[str, Any]] = {}
ATTACHMENT_ID_CACHE_TTL = 600  # 10 minutes - INCREASED for debugging

# === –§—É–Ω–∫—Ü—ñ—ó –¥–ª—è –æ–±—Ä–æ–±–∫–∏ –≤–µ–±—Ö—É–∫—ñ–≤ ===

async def handle_webhook(request: web.Request) -> web.Response:
    """
    –ì–æ–ª–æ–≤–Ω–∏–π –æ–±—Ä–æ–±–Ω–∏–∫ –≤–µ–±—Ö—É–∫—ñ–≤ –≤—ñ–¥ Jira.
    
    Args:
        request: –ó–∞–ø–∏—Ç –≤–µ–±—Ö—É–∫–∞
        
    Returns:
        web.Response: –í—ñ–¥–ø–æ–≤—ñ–¥—å –¥–ª—è Jira
    """
    try:
        # Load and validate webhook data
        try:
            webhook_data = await request.json()
            logger.debug(f"Webhook data: {json.dumps(webhook_data, indent=2, ensure_ascii=False)}")
        except ValueError:
            logger.error("Invalid JSON in webhook request")
            return web.json_response({"status": "error", "message": "Invalid JSON"}, status=400)
        
        # –í–∏–∑–Ω–∞—á–∞—î–º–æ —Ç–∏–ø –ø–æ–¥—ñ—ó
        event_type = webhook_data.get('webhookEvent', '')
        if not event_type:
            logger.warning("No event type in request")
            return web.json_response({"status": "error", "message": "Missing event type"}, status=400)
            
        logger.info(f"–û–±—Ä–æ–±–∫–∞ –ø–æ–¥—ñ—ó: {event_type}")
        
        # Validate required fields based on event type
        if not await validate_webhook_data(webhook_data, event_type):
            logger.error(f"Invalid webhook data for event type: {event_type}")
            return web.json_response({"status": "error", "message": "Invalid webhook data"}, status=400)
        
        # Route to appropriate handler
        handler = None
        if event_type == EVENT_ISSUE_UPDATED:
            handler = handle_issue_updated
        elif event_type == EVENT_COMMENT_CREATED:
            handler = handle_comment_created
        elif event_type == EVENT_ISSUE_CREATED:
            handler = handle_issue_created
        elif event_type == EVENT_ATTACHMENT_CREATED:
            handler = handle_attachment_created
        elif event_type in [EVENT_ISSUE_PROPERTY_SET, EVENT_ISSUELINK_CREATED, 
                           EVENT_WORKLOG_CREATED, EVENT_WORKLOG_UPDATED, EVENT_WORKLOG_DELETED,
                           EVENT_USER_CREATED, EVENT_USER_UPDATED]:
            # –õ–æ–≥—É—î–º–æ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ–π–Ω—ñ –ø–æ–¥—ñ—ó –±–µ–∑ –æ–±—Ä–æ–±–∫–∏
            logger.info(f"‚ÑπÔ∏è Info event received: {event_type} - logging only, no action taken")
            issue_key = webhook_data.get('issue', {}).get('key', 'N/A')
            if issue_key != 'N/A':
                logger.info(f"   Issue: {issue_key}")
            return web.json_response({"status": "success", "message": f"Info event logged: {event_type}"})
        else:
            logger.warning(f"Unsupported event type: {event_type}")
            return web.json_response({"status": "error", "message": f"Unsupported event type: {event_type}"}, status=400)
            
        try:
            await handler(webhook_data)
        except Exception as e:
            logger.error(f"Error in {event_type} handler: {str(e)}", exc_info=True)
            # Don't return error to Jira - we've already received the webhook
            # Just log it and return success to prevent retries
            
        return web.json_response({"status": "success", "message": f"Event processed: {event_type}"})
        
    except Exception as e:
        logger.error(f"Error processing webhook: {str(e)}", exc_info=True)
        return web.json_response({"status": "error", "message": "Internal server error"}, status=500)

async def validate_webhook_data(data: Dict[str, Any], event_type: str) -> bool:
    """
    Validates that the webhook data contains all required fields for the given event type.
    
    Args:
        data: The webhook data to validate
        event_type: The type of event being processed
        
    Returns:
        bool: True if the data is valid, False otherwise
    """
    try:
        if event_type == EVENT_ISSUE_UPDATED:
            return bool(
                data.get('issue', {}).get('key') and
                data.get('changelog', {}).get('items')
            )
            
        elif event_type == EVENT_COMMENT_CREATED:
            return bool(
                data.get('issue', {}).get('key') and
                data.get('comment', {}).get('author')
            )
            
        elif event_type == EVENT_ISSUE_CREATED:
            return bool(
                data.get('issue', {}).get('key') and
                data.get('issue', {}).get('fields', {}).get('creator')
            )
            
        elif event_type == EVENT_ATTACHMENT_CREATED:
            return bool(
                data.get('attachment') and
                (data.get('issue', {}).get('key') or
                 # Allow issue key to be extracted from attachment URL
                 any(url_field in data.get('attachment', {}) for url_field in ['self', 'content', 'url']))
            )
        
        # –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ–π–Ω—ñ –ø–æ–¥—ñ—ó - –∑–∞–≤–∂–¥–∏ –≤–∞–ª—ñ–¥–Ω—ñ (–ª–æ–≥—É—î–º–æ –∞–ª–µ –Ω–µ –æ–±—Ä–æ–±–ª—è—î–º–æ)
        elif event_type in [EVENT_ISSUE_PROPERTY_SET, EVENT_ISSUELINK_CREATED,
                           EVENT_WORKLOG_CREATED, EVENT_WORKLOG_UPDATED, EVENT_WORKLOG_DELETED,
                           EVENT_USER_CREATED, EVENT_USER_UPDATED]:
            return True
            
        return False
        
    except Exception as e:
        logger.error(f"Error validating webhook data: {str(e)}", exc_info=True)
        return False

async def handle_issue_updated(webhook_data: Dict[str, Any]) -> None:
    """
    –û–±—Ä–æ–±–∫–∞ –ø–æ–¥—ñ—ó –æ–Ω–æ–≤–ª–µ–Ω–Ω—è –∑–∞–¥–∞—á—ñ –≤ Jira.
    –ü–µ—Ä–µ–≤—ñ—Ä—è—î –∑–º—ñ–Ω—É —Å—Ç–∞—Ç—É—Å—É —Ç–∞ –Ω–∞–¥—Å–∏–ª–∞—î –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—É –≤ Telegram.
    """
    try:
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ –∑–º—ñ–Ω–∏–≤—Å—è —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á—ñ
        changelog = webhook_data.get('changelog', {})
        items = changelog.get('items', [])
        
        # –®—É–∫–∞—î–º–æ –∑–º—ñ–Ω–∏ —Å—Ç–∞—Ç—É—Å—É
        status_change = next((item for item in items if item.get('field') == 'status'), None)
        
        if not status_change:
            logger.info("–ó–º—ñ–Ω–∞ –∑–∞–¥–∞—á—ñ –Ω–µ –ø–æ–≤'—è–∑–∞–Ω–∞ –∑—ñ –∑–º—ñ–Ω–æ—é —Å—Ç–∞—Ç—É—Å—É")
            return
        
        # –û—Ç—Ä–∏–º—É—î–º–æ –¥–∞–Ω—ñ –ø—Ä–æ –Ω–æ–≤–µ –∑–Ω–∞—á–µ–Ω–Ω—è —Å—Ç–∞—Ç—É—Å—É
        new_status = status_change.get('toString', '')
        old_status = status_change.get('fromString', '')
        
        # –û—Ç—Ä–∏–º—É—î–º–æ –¥–∞–Ω—ñ –ø—Ä–æ –∑–∞–¥–∞—á—É
        issue_key = webhook_data.get('issue', {}).get('key', '')
        issue_summary = webhook_data.get('issue', {}).get('fields', {}).get('summary', '')
        
        logger.info(f"–°—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á—ñ {issue_key} –∑–º—ñ–Ω–∏–≤—Å—è –∑ '{old_status}' –Ω–∞ '{new_status}'")
        
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, –≤—ñ–¥ —è–∫–æ–≥–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ –Ω–∞–¥—ñ–π—à–ª–∞ –∑–º—ñ–Ω–∞
        author_info = None
        if 'user' in webhook_data:
            author_info = webhook_data.get('user', {})
        else:
            # –°–ø—Ä–æ–±–∞ –∑–Ω–∞–π—Ç–∏ –∞–≤—Ç–æ—Ä–∞ –≤ —ñ–Ω—à–∏—Ö –º—ñ—Å—Ü—è—Ö
            author_info = webhook_data.get('comment', {}).get('author', {})
            
        # –Ø–∫—â–æ –∑–º—ñ–Ω–∞ –≤—ñ–¥ —Ç–µ—Ö–Ω—ñ—á–Ω–æ–≥–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ - —ñ–≥–Ω–æ—Ä—É—î–º–æ
        if author_info:
            from config.config import JIRA_REPORTER_ACCOUNT_ID
            author_id = author_info.get('accountId', '')
            if author_id == JIRA_REPORTER_ACCOUNT_ID:
                logger.info(f"–ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ –∑–º—ñ–Ω—É —Å—Ç–∞—Ç—É—Å—É –≤—ñ–¥ —Ç–µ—Ö–Ω—ñ—á–Ω–æ–≥–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ (ID: {author_id})")
                return
                
        # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ –≤ Telegram –∑–∞ –∫–ª—é—á–µ–º –∑–∞–¥–∞—á—ñ
        user_data = await find_user_by_jira_issue_key(issue_key)
        
        if not user_data:
            logger.warning(f"–ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ Telegram –¥–ª—è –∑–∞–¥–∞—á—ñ {issue_key}")
            return
        
        # –ì–æ—Ç—É—î–º–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –ø—Ä–æ –∑–º—ñ–Ω—É —Å—Ç–∞—Ç—É—Å—É
        message = (
            f"üìù –°—Ç–∞—Ç—É—Å –ó–∞–¥–∞—á—ñ:<b>{issue_key}</b> –æ–Ω–æ–≤–ª–µ–Ω–æ: <b>{new_status}</b>\n"
        )

        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è —î –¥—É–±–ª—ñ–∫–∞—Ç–æ–º
        if is_duplicate_message(issue_key, message):
            logger.info(f"–ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ –¥—É–±–ª—ñ–∫–∞—Ç –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –¥–ª—è –∑–∞–¥–∞—á—ñ {issue_key}")
            return
        
        # –î–æ–¥–∞—î–º–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –¥–æ –∫–µ—à—É
        add_message_to_cache(issue_key, message)
        
        # –ù–∞–¥—Å–∏–ª–∞—î–º–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—É –≤ Telegram
        await send_telegram_message(user_data['telegram_id'], message)
        
    except Exception as e:
        logger.error(f"–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ –∑–º—ñ–Ω–∏ —Å—Ç–∞—Ç—É—Å—É –∑–∞–¥–∞—á—ñ: {str(e)}", exc_info=True)

async def handle_comment_created(webhook_data: Dict[str, Any]) -> None:
    """
    –û–±—Ä–æ–±–∫–∞ –ø–æ–¥—ñ—ó —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –∫–æ–º–µ–Ω—Ç–∞—Ä—è –≤ Jira.
    –ü–µ—Ä–µ—Å–∏–ª–∞—î –∫–æ–º–µ–Ω—Ç–∞—Ä –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—É –≤ Telegram.
    """
    try:
        # Get comment and issue data
        comment = webhook_data.get('comment', {})
        issue_key = webhook_data.get('issue', {}).get('key', '')
        
        logger.info(f"Processing new comment for issue {issue_key}")
        logger.debug(f"Full webhook data: {json.dumps(webhook_data, indent=2, ensure_ascii=False)}")
        
        # Skip if empty comment and no attachments
        comment_body = comment.get('body', '').strip()
        
        # Skip comments from system/bot users
        comment_author = comment.get('author', {})
        author_name = comment_author.get('displayName', '')
        author_id = comment_author.get('accountId', '')
        
        logger.debug(f"Comment author: {author_name} (ID: {author_id})")
        
        from config.config import JIRA_REPORTER_ACCOUNT_ID
        if "Telegram Bot" in author_name or author_id == JIRA_REPORTER_ACCOUNT_ID:
            logger.info(f"Skipping comment from system user: {author_name}")
            return
        
        # Skip comments that start with "*–Ü–º'—è:" or "**–Ü–º'—è:" - these are author headers from bot
        if comment_body and (comment_body.startswith("*–Ü–º'—è:") or comment_body.startswith("**–Ü–º'—è:")):
            logger.info(f"Skipping comment with author header: {comment_body[:50]}...")
            return
        
        # Find Telegram user
        user_data = await find_user_by_jira_issue_key(issue_key)
        if not user_data:
            logger.info(f"No Telegram user found for issue {issue_key} - issue created manually in Jira, skipping notification")
            return
            
        logger.debug(f"Found Telegram user: {user_data}")
        
        # Collect all attachments from different possible locations
        attachments = []
        
        logger.info("üîç SEARCHING FOR ATTACHMENTS IN ALL LOCATIONS:")
        
        # –ö–†–ò–¢–ò–ß–ù–ï –í–ò–ü–†–ê–í–õ–ï–ù–ù–Ø: –ó–±—ñ–ª—å—à–µ–Ω–∞ –∑–∞—Ç—Ä–∏–º–∫–∞ –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è –∫–µ—à—É–≤–∞–Ω–Ω—è –í–°–Ü–• —Ñ–∞–π–ª—ñ–≤
        logger.info("‚è≥ Waiting 5 seconds for all attachment_created events to complete...")
        await asyncio.sleep(5)  # –ó–±—ñ–ª—å—à–µ–Ω–æ –∑ 2 –¥–æ 5 —Å–µ–∫—É–Ω–¥ –¥–ª—è –ø–æ–≤–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è –≤—Å—ñ—Ö attachment_created –ø–æ–¥—ñ–π
        
        # –ù–û–í–ò–ù–ö–ê: –°–ø–æ—á–∞—Ç–∫—É –ø–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –∑–∞–∫–µ—à–æ–≤–∞–Ω—ñ –≤–∫–ª–∞–¥–µ–Ω–Ω—è + ID-based –ø–æ—à—É–∫
        comment_timestamp = time.time()  # –ü—Ä–∏–±–ª–∏–∑–Ω–∏–π —á–∞—Å –∫–æ–º–µ–Ω—Ç–∞—Ä—è
        
        # –û—Ç—Ä–∏–º—É—î–º–æ embedded attachments –¥–ª—è –¥–æ–ø–æ–º–æ–≥–∏ –≤ –ø–æ—à—É–∫—É
        embedded_attachments = []
        if comment_body:
            embedded_attachments = extract_embedded_attachments(comment_body)
            logger.info(f"üìé Found {len(embedded_attachments)} embedded attachments in comment")
            for i, att in enumerate(embedded_attachments):
                filename = att.get('filename', 'unknown')
                logger.info(f"   {i+1}. {filename}")
        
        # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –Ω–æ–≤—É —Å—Ç—Ä–∞—Ç–µ–≥—ñ—é –ø–æ—à—É–∫—É
        cached_attachments = find_cached_attachments_by_patterns(issue_key, embedded_attachments, comment_timestamp)
        if cached_attachments:
            logger.info(f"üì¶ Found {len(cached_attachments)} cached attachments via enhanced search:")
            for i, att in enumerate(cached_attachments):
                filename = att.get('filename', 'unknown')
                att_id = att.get('id', 'no-id')
                logger.info(f"   üéØ CACHED {i+1}. {filename} (ID: {att_id})")
            attachments.extend(cached_attachments)
            
            # –ö–†–ò–¢–ò–ß–ù–ê –ü–ï–†–ï–í–Ü–†–ö–ê: –ß–∏ –≤—Å—ñ embedded —Ñ–∞–π–ª–∏ –∑–Ω–∞–π–¥–µ–Ω—ñ?
            if embedded_attachments:
                found_filenames = {att.get('filename', '') for att in cached_attachments}
                embedded_filenames = {att.get('filename', '') for att in embedded_attachments}
                missing_files = embedded_filenames - found_filenames
                
                if missing_files:
                    logger.warning(f"‚ö†Ô∏è MISSING FILES DETECTED: {len(missing_files)} embedded files not found in cache!")
                    for missing_file in missing_files:
                        logger.warning(f"   ‚ùå MISSING: {missing_file}")
                    
                    # –î–æ–¥–∞—Ç–∫–æ–≤–∞ —Å–ø—Ä–æ–±–∞ –∑–Ω–∞–π—Ç–∏ —á–µ—Ä–µ–∑ —Ä–æ–∑—à–∏—Ä–µ–Ω–∏–π –ø–æ—à—É–∫
                    logger.info("üîÑ Attempting additional search for missing files...")
                    additional_search = find_cached_attachments_by_patterns(
                        issue_key, 
                        [{'filename': f} for f in missing_files], 
                        comment_timestamp,
                        extend_time_window=True  # –†–æ–∑—à–∏—Ä—é—î–º–æ —á–∞—Å–æ–≤–µ –≤—ñ–∫–Ω–æ
                    )
                    
                    if additional_search:
                        logger.info(f"‚úÖ RECOVERY: Found {len(additional_search)} additional files")
                        for att in additional_search:
                            logger.info(f"   ‚úÖ RECOVERED: {att.get('filename', 'unknown')} (ID: {att.get('id', 'no-id')})")
                        attachments.extend(additional_search)
                    else:
                        logger.error(f"‚ùå CRITICAL: Unable to recover {len(missing_files)} missing files")
                else:
                    logger.info("‚úÖ ALL EMBEDDED FILES FOUND in cache")
        else:
            logger.warning(f"‚ùå NO CACHED ATTACHMENTS FOUND with enhanced search")
        
        # 1. Direct attachments on the comment
        if 'attachment' in comment:
            direct_attachments = comment.get('attachment', [])
            logger.info(f"üìé Comment direct attachments: {len(direct_attachments)}")
            attachments.extend(direct_attachments)
            
        if 'attachments' in comment:
            plural_attachments = comment.get('attachments', [])
            logger.info(f"üìé Comment plural attachments: {len(plural_attachments)}")
            attachments.extend(plural_attachments)
            
        # 2. Issue-level attachments (CRITICAL FIX - files are often attached to issue, not comment)
        if 'issue' in webhook_data and 'fields' in webhook_data['issue']:
            issue_attachments = webhook_data['issue']['fields'].get('attachment', [])
            logger.info(f"üìé Issue-level attachments: {len(issue_attachments)}")
            if issue_attachments:
                for i, att in enumerate(issue_attachments):
                    filename = att.get('filename', 'unknown')
                    att_id = att.get('id', 'no-id')
                    logger.info(f"   {i+1}. {filename} (ID: {att_id})")
                attachments.extend(issue_attachments)
            
        # 3. Additional embedded attachments (—è–∫—â–æ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω—ñ —Ä–∞–Ω—ñ—à–µ)
        if comment_body and not embedded_attachments:
            embedded = extract_embedded_attachments(comment_body)
            logger.info(f"üìé Additional embedded attachments in comment body: {len(embedded)}")
            if embedded:
                for i, att in enumerate(embedded):
                    filename = att.get('filename', 'unknown')
                    att_id = att.get('id', 'no-id')
                    logger.info(f"   {i+1}. {filename} (ID: {att_id})")
                logger.debug(f"Additional embedded attachments: {json.dumps(embedded, indent=2)}")
                attachments.extend(embedded)
                
        # 4. Special content structure (some Jira versions)
        if 'content' in comment:
            content = comment.get('content', [])
            content_attachments = []
            for item in content:
                if isinstance(item, dict) and 'attachment' in item:
                    content_attachments.append(item['attachment'])
            
            logger.info(f"üìé Content structure attachments: {len(content_attachments)}")
            if content_attachments:
                for i, att in enumerate(content_attachments):
                    filename = att.get('filename', 'unknown')
                    att_id = att.get('id', 'no-id')
                    logger.info(f"   {i+1}. {filename} (ID: {att_id})")
                    logger.debug(f"Found attachment in content structure: {json.dumps(att, indent=2)}")
                attachments.extend(content_attachments)
                    
        # 5. –í–ê–ñ–õ–ò–í–û: –ù–ï –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –≤—Å—ñ –≤–∫–ª–∞–¥–µ–Ω–Ω—è –∑–∞–¥–∞—á—ñ —è–∫ fallback!
        # –Ø–∫—â–æ –Ω–µ–º–∞—î –≤–∫–ª–∞–¥–µ–Ω—å —É –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ, –∑–Ω–∞—á–∏—Ç—å –∫–æ–º–µ–Ω—Ç–∞—Ä –ë–ï–ó –≤–∫–ª–∞–¥–µ–Ω—å
        if not attachments and issue_key:
            logger.info(f"üì° No attachments found in webhook for comment - this is normal for text-only comments")
            logger.info(f"‚ùå SKIPPING API fallback to prevent sending ALL issue attachments")
            # –ù–ï —Ä–æ–±–∏–º–æ API –∑–∞–ø–∏—Ç - —Ü–µ –ø—Ä–∏–∑–≤–µ–¥–µ –¥–æ –ø–µ—Ä–µ—Å–∏–ª–∞–Ω–Ω—è –≤—Å—ñ—Ö –≤–∫–ª–∞–¥–µ–Ω—å –∑–∞–¥–∞—á—ñ!
        
        # Remove duplicates by ID
        unique_attachments = []
        seen_ids = set()
        
        for att in attachments:
            att_id = att.get('id')
            if att_id and att_id not in seen_ids:
                unique_attachments.append(att)
                seen_ids.add(att_id)
            elif not att_id:  # No ID, check by filename
                filename = att.get('filename', '')
                if filename and filename not in [a.get('filename') for a in unique_attachments]:
                    unique_attachments.append(att)
        
        logger.info(f"üìã After deduplication: {len(unique_attachments)} unique attachments")
        attachments = unique_attachments
                    
        # Log attachment info
        if attachments:
            logger.info(f"üéØ TOTAL FOUND: {len(attachments)} total attachments")
            for idx, att in enumerate(attachments, 1):
                filename = att.get('filename', 'unknown')
                att_id = att.get('id', 'no-id')
                att_url = att.get('content', att.get('self', ''))
                mime_type = att.get('mimeType', att.get('contentType', 'unknown'))
                logger.info(f"üìé Attachment {idx}: {filename}")
                logger.info(f"   - ID: {att_id}")
                logger.info(f"   - MIME: {mime_type}")
                logger.info(f"   - URL: {att_url}")
                logger.debug(f"   - Full data: {json.dumps(att, indent=2)}")
        else:
            logger.warning("‚ùå NO ATTACHMENTS FOUND IN WEBHOOK!")
            # Log the full webhook for debugging
            logger.debug(f"Full webhook data: {json.dumps(webhook_data, indent=2, ensure_ascii=False)}")
                
        # Prepare and send the message
        message_parts = []
        
        # Add comment text if present
        if comment_body:
            formatted_text = format_comment_text(comment_body)
            if formatted_text:  # Only add if there's actual content after formatting
                message_parts.extend([
                    "üîî <b>–í—ñ–¥–ø–æ–≤—ñ–¥—å —Ç–µ—Ö–ø—ñ–¥—Ç—Ä–∏–º–∫–∏:</b>\n\n",
                    formatted_text
                ])
            
        # Send main message (only if there's text content)
        message = "\n".join(message_parts)
        if message:
            await send_telegram_message(user_data['telegram_id'], message)
            
        # Process and send attachments
        if attachments:
            logger.info("Starting to process attachments")
            #await process_attachments(attachments, issue_key, user_data['telegram_id'])
            await process_attachments_universal(attachments, issue_key, user_data['telegram_id'])
        
        # –û—á–∏—â–∞—î–º–æ –∫–µ—à –≤–∫–ª–∞–¥–µ–Ω—å –ø—ñ—Å–ª—è –æ–±—Ä–æ–±–∫–∏ –∫–æ–º–µ–Ω—Ç–∞—Ä—è  
        cleanup_attachment_cache()
            
    except Exception as e:
        logger.error(f"Error processing new comment: {str(e)}", exc_info=True)
        import traceback
        logger.error(f"Full traceback: {traceback.format_exc()}")

async def handle_issue_created(webhook_data: Dict[str, Any]) -> None:
    """
    –û–±—Ä–æ–±–∫–∞ –ø–æ–¥—ñ—ó —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –∑–∞–¥–∞—á—ñ –≤ Jira.
    –ù–∞–¥—Å–∏–ª–∞—î –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –≤ Telegram, —è–∫—â–æ –∑–∞–¥–∞—á–∞ —Å—Ç–≤–æ—Ä–µ–Ω–∞ –Ω–µ —á–µ—Ä–µ–∑ –±–æ—Ç.
    """
    try:
        # –û—Ç—Ä–∏–º—É—î–º–æ –¥–∞–Ω—ñ –ø—Ä–æ –∑–∞–¥–∞—á—É
        issue = webhook_data.get('issue', {})
        issue_key = issue.get('key', '')
        issue_summary = issue.get('fields', {}).get('summary', '')
        issue_creator = issue.get('fields', {}).get('creator', {}).get('displayName', '')
        
        logger.info(f"–°—Ç–≤–æ—Ä–µ–Ω–∞ –Ω–æ–≤–∞ –∑–∞–¥–∞—á–∞ {issue_key} –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–µ–º {issue_creator}: {issue_summary[:100]}...")
        
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ –∑–∞–¥–∞—á–∞ –Ω–µ —Å—Ç–≤–æ—Ä–µ–Ω–∞ —á–µ—Ä–µ–∑ –±–æ—Ç
        if "Telegram Bot" in issue_creator:
            logger.info(f"–ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –ø—Ä–æ –∑–∞–¥–∞—á—É, —Å—Ç–≤–æ—Ä–µ–Ω—É —á–µ—Ä–µ–∑ –±–æ—Ç")
            return
        
        # –û—Ç—Ä–∏–º—É—î–º–æ telegram_id –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ –∑—ñ —Å–ø–µ—Ü—ñ–∞–ª—å–Ω–æ–≥–æ –ø–æ–ª—è –∞–±–æ —á–µ—Ä–µ–∑ –ø–æ—à—É–∫
        telegram_id = None
        
        # –®—É–∫–∞—î–º–æ –≤ —Å–ø–µ—Ü—ñ–∞–ª—å–Ω–∏—Ö –ø–æ–ª—è—Ö
        custom_fields = issue.get('fields', {})
        for field_key, field_value in custom_fields.items():
            if field_key == 'customfield_10145':  # telegram_id –ø–æ–ª–µ
                telegram_id = field_value
                break
        
        if not telegram_id:
            logger.warning(f"–ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ Telegram ID –¥–ª—è –∑–∞–¥–∞—á—ñ {issue_key}")
            return
        
        # –§–æ—Ä–º–∞—Ç—É—î–º–æ –¥–µ—Ç–∞–ª—ñ –∑–∞–¥–∞—á—ñ –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é –Ω–∞—à–∏—Ö —Ñ—É–Ω–∫—Ü—ñ–π —Ñ–æ—Ä–º–∞—Ç—É–≤–∞–Ω–Ω—è
        formatted_issue = format_issue_info(issue)
        issue_text = format_issue_text(formatted_issue)
        
        # –ì–æ—Ç—É—î–º–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –ø—Ä–æ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –∑–∞–¥–∞—á—ñ
        message = (
            f"üÜï <b>–°—Ç–≤–æ—Ä–µ–Ω–æ –Ω–æ–≤—É –∑–∞–¥–∞—á—É:{issue_key}</b>\n\n"
        )
        
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è —î –¥—É–±–ª—ñ–∫–∞—Ç–æ–º
        if is_duplicate_message(issue_key, message):
            logger.info(f"–ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ –¥—É–±–ª—ñ–∫–∞—Ç –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –¥–ª—è –∑–∞–¥–∞—á—ñ {issue_key}")
            return
        
        # –î–æ–¥–∞—î–º–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –¥–æ –∫–µ—à—É
        add_message_to_cache(issue_key, message)
        
        # –ù–∞–¥—Å–∏–ª–∞—î–º–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—É –≤ Telegram
        await send_telegram_message(telegram_id, message)

    except Exception as e:
        logger.error(f"–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ –Ω–æ–≤–æ—ó –∑–∞–¥–∞—á—ñ: {str(e)}", exc_info=True)

async def handle_attachment_created(webhook_data: Dict[str, Any]) -> None:
    """
    –û–±—Ä–æ–±–∫–∞ –ø–æ–¥—ñ—ó —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –≤–∫–ª–∞–¥–µ–Ω–Ω—è –≤ Jira.
    –ó–ú–Ü–ù–ï–ù–û: –¢–µ–ø–µ—Ä –∫–µ—à—É—î –≤–∫–ª–∞–¥–µ–Ω–Ω—è –∑–∞–º—ñ—Å—Ç—å –Ω–µ–≥–∞–π–Ω–æ—ó –≤—ñ–¥–ø—Ä–∞–≤–∫–∏.
    –í–∫–ª–∞–¥–µ–Ω–Ω—è –±—É–¥—É—Ç—å –≤—ñ–¥–ø—Ä–∞–≤–ª–µ–Ω—ñ –ø—Ä–∏ –æ–±—Ä–æ–±—Ü—ñ comment_created –ø–æ–¥—ñ—ó.
    """
    try:
        # –õ–æ–≥—É—î–º–æ –ø–æ–≤–Ω—ñ –¥–∞–Ω—ñ –≤–µ–±—Ö—É–∫–∞ –¥–ª—è –≤—ñ–¥–ª–∞–≥–æ–¥–∂–µ–Ω–Ω—è
        logger.info(f"üîî ATTACHMENT_CREATED EVENT RECEIVED")
        logger.debug(f"–û—Ç—Ä–∏–º–∞–Ω–æ –ø–æ–¥—ñ—é attachment_created: {json.dumps(webhook_data, indent=2)}")
        
        # –û—Ç—Ä–∏–º—É—î–º–æ –¥–∞–Ω—ñ –ø—Ä–æ –≤–∫–ª–∞–¥–µ–Ω–Ω—è
        attachment = webhook_data.get('attachment', {})
        if isinstance(attachment, list):
            attachment = attachment[0] if attachment else {}
        if not attachment:
            logger.warning("–û—Ç—Ä–∏–º–∞–Ω–æ –ø–æ–¥—ñ—é attachment_created –±–µ–∑ –¥–∞–Ω–∏—Ö –≤–∫–ª–∞–¥–µ–Ω–Ω—è")
            return
            
        attachment_id = attachment.get('id', '')
        filename = attachment.get('filename', 'unknown_file')
        
        logger.info(f"üìé Processing attachment_created: {filename} (ID: {attachment_id})")
        
        # –û—Ç—Ä–∏–º—É—î–º–æ issue_key –¥–ª—è –∫–µ—à—É–≤–∞–Ω–Ω—è
        issue_key = None
        
        # –°–ø–æ—á–∞—Ç–∫—É —à—É–∫–∞—î–º–æ –∫–ª—é—á –∑–∞–¥–∞—á—ñ –≤ –¥–∞–Ω–∏—Ö –≤–µ–±—Ö—É–∫–∞
        if 'issue' in webhook_data:
            issue = webhook_data.get('issue', {})
            issue_key = issue.get('key', '')
            logger.info(f"‚úÖ Found issue key in webhook data: {issue_key}")
        
        # –ù–û–í–ò–ô FALLBACK: –Ø–∫—â–æ –Ω–µ–º–∞—î issue –≤ webhook, —Å–ø—Ä–æ–±—É—î–º–æ —á–µ—Ä–µ–∑ issueId
        if not issue_key and 'issueId' in webhook_data:
            issue_id = webhook_data.get('issueId', '')
            logger.info(f"üîç Found issueId in webhook, will try to resolve: {issue_id}")
            # issueId –∑–∞–∑–≤–∏—á–∞–π –Ω–µ –º—ñ—Å—Ç–∏—Ç—å –∫–ª—é—á, –∞–ª–µ –º–æ–∂–µ –±—É—Ç–∏ –∫–æ—Ä–∏—Å–Ω–∏–º –¥–ª—è API –∑–∞–ø–∏—Ç—ñ–≤
            
        # –ù–û–í–ò–ô FALLBACK: –ü–µ—Ä–µ–≤—ñ—Ä–∏–º–æ attachment –¥–∞–Ω—ñ –Ω–∞ –Ω–∞—è–≤–Ω—ñ—Å—Ç—å issue –ø–æ—Å–∏–ª–∞–Ω—å
        if not issue_key and attachment:
            for url_field in ['self', 'content', 'url']:
                url = attachment.get(url_field, '')
                if url and '/issue/' in url:
                    # –°–ø—Ä–æ–±—É–≤–∞—Ç–∏ –≤–∏—Ç—è–≥–Ω—É—Ç–∏ issue key –∑ URL
                    match = re.search(r'/issue/([A-Z]+-\d+)', url)
                    if match:
                        issue_key = match.group(1)
                        logger.info(f"‚úÖ Extracted issue key from attachment URL: {issue_key}")
                        break
        
        # –Ø–∫—â–æ –Ω–µ–º–∞—î –∫–ª—é—á–∞ –≤ webhook, –Ω–∞–º–∞–≥–∞—î–º–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ —á–µ—Ä–µ–∑ API
        if not issue_key and attachment_id:
            logger.info(f"üåê No issue key in webhook, trying API for attachment {attachment_id}")
            issue_key = await get_issue_key_from_attachment_api(attachment_id)
        
        # –Ø–∫—â–æ –≤—Å–µ —â–µ –Ω–µ–º–∞—î –∫–ª—é—á–∞, –Ω–∞–º–∞–≥–∞—î–º–æ—Å—è –≤–∏—Ç—è–≥–Ω—É—Ç–∏ –∑ URL
        if not issue_key:
            logger.info(f"üîç Trying to extract issue key from attachment URLs")
            issue_key = extract_issue_key_from_urls(attachment)
        
        if not issue_key:
            logger.warning(f"‚ùå Cannot determine issue key for attachment {attachment_id}. Using ID-based caching.")
            logger.debug(f"Available webhook data fields: {list(webhook_data.keys())}")
            logger.debug(f"Attachment data: {json.dumps(attachment, indent=2)}")
            
            # FALLBACK: –ö–µ—à—É—î–º–æ –∑–∞ attachment_id
            add_attachment_to_id_cache(attachment)
            logger.info(f"üí° Attachment {filename} cached by ID. Will be matched later by filename/timestamp.")
            
            # –û—á–∏—â–∞—î–º–æ —Å—Ç–∞—Ä—ñ –∑–∞–ø–∏—Å–∏ –∑ –∫–µ—à—É
            cleanup_attachment_cache()
            return
        
        # –û–°–ù–û–í–ù–ê –ó–ú–Ü–ù–ê: –ö–µ—à—É—î–º–æ –≤–∫–ª–∞–¥–µ–Ω–Ω—è –∑–∞–º—ñ—Å—Ç—å –Ω–µ–≥–∞–π–Ω–æ—ó –≤—ñ–¥–ø—Ä–∞–≤–∫–∏
        logger.info(f"üîµ ATTEMPTING TO CACHE: {filename} for issue {issue_key}")
        logger.info(f"üîµ CACHE STATE BEFORE: {len(PENDING_ATTACHMENTS_CACHE)} issues, {sum(len(v) for v in PENDING_ATTACHMENTS_CACHE.values())} total attachments")
        
        add_attachment_to_cache(issue_key, attachment)
        
        logger.info(f"üîµ CACHE STATE AFTER: {len(PENDING_ATTACHMENTS_CACHE)} issues, {sum(len(v) for v in PENDING_ATTACHMENTS_CACHE.values())} total attachments")
        logger.info(f"‚úÖ Attachment {filename} cached for issue {issue_key}")
        logger.info(f"üí° Waiting for comment_created event to process attachment...")
        
        # –û—á–∏—â–∞—î–º–æ —Å—Ç–∞—Ä—ñ –∑–∞–ø–∏—Å–∏ –∑ –∫–µ—à—É
        cleanup_attachment_cache()
        
    except Exception as e:
        logger.error(f"‚ùå Error in handle_attachment_created: {str(e)}", exc_info=True)

async def get_issue_key_from_attachment_api(attachment_id: str) -> Optional[str]:
    """
    –û—Ç—Ä–∏–º—É—î issue_key —á–µ—Ä–µ–∑ REST API –∑–∞ attachment_id.
    
    Args:
        attachment_id: ID –≤–∫–ª–∞–¥–µ–Ω–Ω—è
        
    Returns:
        str|None: –ö–ª—é—á –∑–∞–¥–∞—á—ñ –∞–±–æ None —è–∫—â–æ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ
    """
    if not attachment_id:
        logger.warning("Empty attachment_id provided to get_issue_key_from_attachment_api")
        return None
        
    max_retries = 2  # –ó–º–µ–Ω—à–µ–Ω–æ –¥–ª—è —à–≤–∏–¥—à–æ—Å—Ç—ñ
    base_retry_delay = 0.5  # –®–≤–∏–¥—à—ñ retry
    
    # –ö–†–ò–¢–ò–ß–ù–ï –í–ò–ü–†–ê–í–õ–ï–ù–ù–Ø: –ù–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ –¥–æ–º–µ–Ω —â–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ –ø–æ–¥–≤—ñ–π–Ω–æ–≥–æ https://
    from src.jira_attachment_utils import normalize_jira_domain
    domain = normalize_jira_domain(JIRA_DOMAIN)
    api_url = f"https://{domain}/rest/api/3/attachment/{attachment_id}"
    
    auth = httpx.BasicAuth(JIRA_EMAIL, JIRA_API_TOKEN)
    headers = {
        'X-Atlassian-Token': 'no-check',
        'Accept': 'application/json',
        'Content-Type': 'application/json',
        'Connection': 'keep-alive'
    }
    
    logger.info(f"üåê Attempting API call: {api_url}")
    
    for attempt in range(max_retries):
        try:
            async with httpx.AsyncClient(
                timeout=15.0,  # –ö–æ—Ä–æ—Ç—à–∏–π timeout
                auth=auth,
                verify=True,
                trust_env=True
            ) as client:
                response = await client.get(api_url, headers=headers)
                
                if response.status_code == 404:
                    logger.warning(f"Attachment {attachment_id} not found (404)")
                    return None
                    
                response.raise_for_status()
                attachment_info = response.json()
                
                logger.debug(f"API Response: {json.dumps(attachment_info, indent=2)}")
                
                # –í —Ä—ñ–∑–Ω–∏—Ö –≤–µ—Ä—Å—ñ—è—Ö Jira –º–æ–∂–µ –±—É—Ç–∏ —Ä—ñ–∑–Ω–µ –ø–æ–ª–µ
                for field in ['issueId', 'issueKey', 'issue']:
                    if field in attachment_info:
                        value = attachment_info[field]
                        if isinstance(value, dict):
                            issue_key = value.get('key', '')
                        else:
                            issue_key = str(value)
                        if issue_key and re.match(r'^[A-Z]+-\d+$', issue_key):
                            logger.info(f"üîç Found issue key via API: {issue_key}")
                            return issue_key
                
                logger.warning(f"No valid issue key found in API response for attachment {attachment_id}")
                return None
                
        except httpx.ConnectError as conn_error:
            logger.warning(f"Connection error (attempt {attempt + 1}/{max_retries}): {str(conn_error)}")
            if attempt < max_retries - 1:
                retry_delay = base_retry_delay * (2 ** attempt)
                logger.info(f"Waiting {retry_delay} seconds before retry...")
                await asyncio.sleep(retry_delay)
                continue
        except httpx.HTTPError as http_error:
            logger.warning(f"HTTP error (attempt {attempt + 1}/{max_retries}): {str(http_error)}")
            if attempt < max_retries - 1:
                retry_delay = base_retry_delay * (2 ** attempt)
                await asyncio.sleep(retry_delay)
                continue
        except Exception as e:
            logger.error(f"Unexpected error accessing Jira API: {str(e)}")
            break
    
    logger.error(f"Failed to get issue key for attachment {attachment_id} after {max_retries} attempts")
    return None

def extract_issue_key_from_urls(attachment: Dict[str, Any]) -> Optional[str]:
    """
    –í–∏—Ç—è–≥—É—î issue_key –∑ URL –≤–∫–ª–∞–¥–µ–Ω–Ω—è.
    
    Args:
        attachment: –î–∞–Ω—ñ –≤–∫–ª–∞–¥–µ–Ω–Ω—è
        
    Returns:
        str|None: –ö–ª—é—á –∑–∞–¥–∞—á—ñ –∞–±–æ None —è–∫—â–æ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ  
    """
    urls_to_check = set()
    
    # –ó–±–∏—Ä–∞—î–º–æ –≤—Å—ñ –º–æ–∂–ª–∏–≤—ñ URL
    for field in ['self', 'content', 'url']:
        url = attachment.get(field)
        if url:
            urls_to_check.add(url)
    
    # –î–æ–¥–∞—î–º–æ –¥–æ–¥–∞—Ç–∫–æ–≤—ñ URL
    attachment_id = attachment.get('id', '')
    if attachment_id:
        # –í–ò–ü–†–ê–í–õ–ï–ù–ù–Ø: –ù–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ –¥–æ–º–µ–Ω
        from src.jira_attachment_utils import normalize_jira_domain
        domain = normalize_jira_domain(JIRA_DOMAIN)
        urls_to_check.add(f"https://{domain}/secure/attachment/{attachment_id}")
        urls_to_check.add(f"https://{domain}/rest/api/3/attachment/{attachment_id}")
    
    patterns = [
        r'/issue/([^/]+)/attachment',
        r'/([A-Z]+-\d+)/attachments',
        r'/secure/attachment/[0-9a-f-]+/([A-Z]+-\d+)',
        r'/projects/[^/]+/issues/([^/]+)',
        r'/([A-Z]+-\d+)/content',
        r'selectedIssue=([A-Z]+-\d+)',
        r'issueKey=([A-Z]+-\d+)'
    ]
    
    for url in urls_to_check:
        for pattern in patterns:
            match = re.search(pattern, url)
            if match:
                found_key = match.group(1)
                if re.match(r'^[A-Z]+-\d+$', found_key):
                    logger.info(f"üîç Extracted issue key from URL: {found_key}")
                    return found_key
    
    return None

# === –î–æ–ø–æ–º—ñ–∂–Ω—ñ —Ñ—É–Ω–∫—Ü—ñ—ó ===

async def send_telegram_message(chat_id: str, text: str, file_data: Optional[tuple] = None) -> bool:
    """
    –ù–∞–¥—Å–∏–ª–∞—î –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—É –≤ Telegram.
    
    Args:
        chat_id: ID —á–∞—Ç—É –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ –≤ Telegram
        text: –¢–µ–∫—Å—Ç –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è
        file_data: –ö–æ—Ä—Ç–µ–∂ (filename, file_content, mime_type) –¥–ª—è –Ω–∞–¥—Å–∏–ª–∞–Ω–Ω—è —Ñ–∞–π–ª—É
        
    Returns:
        bool: True —è–∫—â–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –Ω–∞–¥—ñ—Å–ª–∞–Ω–æ —É—Å–ø—ñ—à–Ω–æ
    """
    try:
        # –ë–∞–∑–æ–≤—ñ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –¥–ª—è HTTP –∫–ª—ñ—î–Ω—Ç–∞
        base_url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}"
        
        # –î–ª—è —Ñ–∞–π–ª—ñ–≤ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —Å–ø–µ—Ü—ñ–∞–ª—å–Ω—É –æ–±—Ä–æ–±–∫—É
        if file_data:
            filename, file_content, mime_type = file_data
            if not file_content:
                logger.error("–§–∞–π–ª –ø–æ—Ä–æ–∂–Ω—ñ–π –∞–±–æ –≤—ñ–¥—Å—É—Ç–Ω—ñ–π")
                return False
                
            # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ httpx –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∏—Ö –∑–∞–ø–∏—Ç—ñ–≤ –∑ –ø—ñ–¥–≤–∏—â–µ–Ω–∏–º timeout
            async with httpx.AsyncClient(timeout=60.0) as client:
                try:
                    # –í–∏–∑–Ω–∞—á–∞—î–º–æ –º–µ—Ç–æ–¥ –≤—ñ–¥–ø—Ä–∞–≤–∫–∏ –≤ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ –≤—ñ–¥ —Ç–∏–ø—É —Ñ–∞–π–ª—É
                    method = "sendDocument"  # Default method
                    file_param = "document"  # Default parameter name
                    
                    # Select appropriate method based on MIME type and file size
                    if mime_type.startswith('image/'):
                        if len(file_content) <= 10 * 1024 * 1024:  # Max 10MB for photos
                            method = "sendPhoto"
                            file_param = "photo"
                            
                    elif mime_type.startswith('video/'):
                        if len(file_content) <= 50 * 1024 * 1024:  # Max 50MB for videos
                            method = "sendVideo"
                            file_param = "video"
                            
                    elif mime_type.startswith('audio/'):
                        if len(file_content) <= 50 * 1024 * 1024:  # Max 50MB for audio
                            method = "sendAudio"
                            file_param = "audio"
                    
                    logger.debug(f"Using Telegram API method: {method}")
                    
                    # –ì–æ—Ç—É—î–º–æ –¥–∞–Ω—ñ –¥–ª—è –≤—ñ–¥–ø—Ä–∞–≤–∫–∏
                    files = {
                        file_param: (filename, BytesIO(file_content), mime_type)
                    }
                    data = {
                        'chat_id': chat_id,
                        'caption': text[:1024] if text else None,  # Limit caption to 1024 chars
                        'parse_mode': 'HTML'
                    }
                    
                    # For large files, set a longer timeout
                    file_size_mb = len(file_content) / (1024 * 1024)
                    timeout = max(30, min(300, int(file_size_mb * 5)))  # 5 seconds per MB, min 30s, max 300s
                    
                    logger.debug(f"Sending file {filename} ({mime_type}) of size {file_size_mb:.2f} MB with {timeout}s timeout")
                    logger.debug(f"Request data: {data}")
                    
                    async with httpx.AsyncClient(timeout=timeout) as client:
                        response = await client.post(f"{base_url}/{method}", data=data, files=files)
                        logger.debug(f"API Response status: {response.status_code}")
                        
                        response.raise_for_status()
                        response_json = response.json()
                        
                        if not response_json.get('ok'):
                            error_msg = response_json.get('description', 'Unknown error')
                            logger.error(f"Telegram API error: {error_msg}")
                            
                            # If file is too large for selected method, try sendDocument
                            if 'file is too big' in error_msg.lower() and method != "sendDocument":
                                logger.info(f"File too big for {method}, falling back to sendDocument")
                                files = {
                                    'document': (filename, BytesIO(file_content), mime_type)
                                }
                                response = await client.post(f"{base_url}/sendDocument", data=data, files=files)
                                response.raise_for_status()
                                response_json = response.json()
                        
                        logger.info(f"File {filename} sent successfully")
                        logger.debug(f"Telegram API response: {json.dumps(response_json, indent=2)}")
                        
                        return True
                        
                except Exception as e:
                    logger.error(f"Error sending file {filename}: {str(e)}", exc_info=True)
                    
                    # Try to get more info about the error
                    error_details = str(e)
                    try:
                        if hasattr(e, 'response') and e.response:
                            error_details = f"{e} - Response: {e.response.text}"
                    except:
                        pass
                    
                    logger.error(f"Error details: {error_details}")
                    
                    # If file is too large, try to send as a link
                    if 'Request entity too large' in str(e) or 'file is too big' in str(e).lower():
                        logger.info("File too large for Telegram, sending as a link")
                        link_text = f"{text}\n\n‚ö†Ô∏è <i>–§–∞–π–ª –∑–∞–≤–µ–ª–∏–∫–∏–π –¥–ª—è –Ω–∞–¥—Å–∏–ª–∞–Ω–Ω—è –≤ Telegram. " \
                                  f"–ë—É–¥—å –ª–∞—Å–∫–∞, –∑–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ –π–æ–≥–æ –±–µ–∑–ø–æ—Å–µ—Ä–µ–¥–Ω—å–æ –∑ Jira.</i>"
                        return await send_telegram_message(chat_id, link_text)
                    
                    return False
        
        # –î–ª—è –∑–≤–∏—á–∞–π–Ω–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤–∏—Ö –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å
        else:
            # –û–±–º–µ–∂—É—î–º–æ –¥–æ–≤–∂–∏–Ω—É –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –¥–æ 4096 —Å–∏–º–≤–æ–ª—ñ–≤ (–ª—ñ–º—ñ—Ç Telegram)
            if len(text) > 4096:
                text = text[:4093] + '...'
                
            data = {
                'chat_id': chat_id,
                'text': text,
                'parse_mode': 'HTML'
            }
            
            # –ù–∞–¥—Å–∏–ª–∞—î–º–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è
            async with httpx.AsyncClient() as client:
                response = await client.post(f"{base_url}/sendMessage", json=data)
                response.raise_for_status()
                
                logger.debug(f"Message sent successfully: {text[:100]}...")
                return True
                
    except Exception as e:
        logger.error(f"Error sending message to Telegram: {str(e)}", exc_info=True)
        return False

async def send_file_as_separate_message(chat_id: str, filename: str, file_content: bytes, mime_type: str, issue_key: str) -> bool:
    """
    –£–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –¥–ª—è –≤—ñ–¥–ø—Ä–∞–≤–∫–∏ —Ñ–∞–π–ª—ñ–≤ —è–∫ –æ–∫—Ä–µ–º–∏—Ö –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å –≤ Telegram.
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –≤–∏–±–∏—Ä–∞—î –Ω–∞–π–∫—Ä–∞—â–∏–π –º–µ—Ç–æ–¥ API –≤ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ –≤—ñ–¥ —Ç–∏–ø—É —Ñ–∞–π–ª—É.
    
    Args:
        chat_id: ID —á–∞—Ç—É –≤ Telegram
        filename: –Ü–º'—è —Ñ–∞–π–ª—É
        file_content: –í–º—ñ—Å—Ç —Ñ–∞–π–ª—É –≤ –±–∞–π—Ç–∞—Ö
        mime_type: MIME —Ç–∏–ø —Ñ–∞–π–ª—É
        issue_key: –ö–ª—é—á –∑–∞–¥–∞—á—ñ Jira
        
    Returns:
        bool: True —è–∫—â–æ —Ñ–∞–π–ª —É—Å–ø—ñ—à–Ω–æ –≤—ñ–¥–ø—Ä–∞–≤–ª–µ–Ω–æ
    """
    try:
        if not file_content:
            logger.error(f"Empty file content for {filename}")
            return False
            
        file_size = len(file_content)
        file_size_mb = file_size / (1024 * 1024)
        
        # –í–∏–∑–Ω–∞—á–∞—î–º–æ —Ç–∏–ø —Ñ–∞–π–ª—É —Ç–∞ —ñ–∫–æ–Ω–∫—É
        if mime_type.startswith('image/'):
            file_type_icon = "üñºÔ∏è"
            file_type_name = "–ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è"
            telegram_method = "sendPhoto"
            size_limit = 10 * 1024 * 1024  # 10MB for photos
        elif mime_type.startswith('video/'):
            file_type_icon = "üé•"
            file_type_name = "–í—ñ–¥–µ–æ"
            telegram_method = "sendVideo" 
            size_limit = 50 * 1024 * 1024  # 50MB for videos
        elif mime_type.startswith('audio/'):
            file_type_icon = "üéµ"
            file_type_name = "–ê—É–¥—ñ–æ"
            telegram_method = "sendAudio"
            size_limit = 50 * 1024 * 1024  # 50MB for audio
        elif mime_type == 'application/vnd.ms-excel' or mime_type == 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet':
            file_type_icon = "üìä"
            file_type_name = "Excel –¥–æ–∫—É–º–µ–Ω—Ç"
            telegram_method = "sendDocument"
            size_limit = 50 * 1024 * 1024  # 50MB for documents
        elif mime_type == 'application/pdf':
            file_type_icon = "üìÑ"
            file_type_name = "PDF –¥–æ–∫—É–º–µ–Ω—Ç"
            telegram_method = "sendDocument"
            size_limit = 50 * 1024 * 1024
        elif mime_type.startswith('text/'):
            file_type_icon = "üìù"
            file_type_name = "–¢–µ–∫—Å—Ç–æ–≤–∏–π —Ñ–∞–π–ª"
            telegram_method = "sendDocument"
            size_limit = 50 * 1024 * 1024
        else:
            file_type_icon = "üìé"
            file_type_name = "–î–æ–∫—É–º–µ–Ω—Ç"
            telegram_method = "sendDocument"
            size_limit = 50 * 1024 * 1024
            
        # –§–æ—Ä–º—É—î–º–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è (simplified without tech support header)
        message = f"{file_type_icon} <b>{filename}</b> ({file_size_mb:.1f} MB)"
        
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —Ä–æ–∑–º—ñ—Ä —Ñ–∞–π–ª—É
        if file_size > size_limit:
            warning_msg = (f"{message}\n\n‚ö†Ô∏è <i>–§–∞–π–ª –∑–∞–≤–µ–ª–∏–∫–∏–π –¥–ª—è –Ω–∞–¥—Å–∏–ª–∞–Ω–Ω—è –≤ Telegram "
                         f"(–æ–±–º–µ–∂–µ–Ω–Ω—è {size_limit/(1024*1024):.0f}MB). "
                         f"–ë—É–¥—å –ª–∞—Å–∫–∞, –∑–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ –π–æ–≥–æ –±–µ–∑–ø–æ—Å–µ—Ä–µ–¥–Ω—å–æ –∑ Jira.</i>")
            return await send_telegram_message(chat_id, warning_msg)
        
        logger.info(f"üì§ Sending {file_type_name.lower()} via {telegram_method}: {filename} ({file_size_mb:.1f}MB)")
        
        # –í—ñ–¥–ø—Ä–∞–≤–ª—è—î–º–æ —Ñ–∞–π–ª —á–µ—Ä–µ–∑ –Ω–∞—è–≤–Ω—É —Ñ—É–Ω–∫—Ü—ñ—é
        return await send_telegram_message(chat_id, message, (filename, file_content, mime_type))
        
    except Exception as e:
        logger.error(f"Error in send_file_as_separate_message for {filename}: {str(e)}", exc_info=True)
        return False

async def process_attachments_universal(attachments: List[Dict[str, Any]], issue_key: str, chat_id: str) -> None:
    """
    –£–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–∞ –æ–±—Ä–æ–±–∫–∞ –≤–∫–ª–∞–¥–µ–Ω—å –∑ –∫–µ—à–æ–≤–∞–Ω–∏–º–∏ —Ç–∞ webhook –¥–∞–Ω–∏–º–∏.
    –û–±'—î–¥–Ω—É—î –∫–µ—à–æ–≤–∞–Ω—ñ –≤–∫–ª–∞–¥–µ–Ω–Ω—è –∑ –æ—Ç—Ä–∏–º–∞–Ω–∏–º–∏ —á–µ—Ä–µ–∑ webhook, –≤–∏–¥–∞–ª—è—î –¥—É–±–ª—ñ–∫–∞—Ç–∏ 
    —Ç–∞ –≤—ñ–¥–ø—Ä–∞–≤–ª—è—î –∫–æ–∂–µ–Ω —Ñ–∞–π–ª —è–∫ –æ–∫—Ä–µ–º–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è.
    
    Args:
        attachments: –°–ø–∏—Å–æ–∫ –≤–∫–ª–∞–¥–µ–Ω—å –∑ webhook
        issue_key: –ö–ª—é—á –∑–∞–¥–∞—á—ñ Jira
        chat_id: ID —á–∞—Ç—É –≤ Telegram
    """
    try:
        logger.info(f"üîÑ Starting universal attachment processing for issue {issue_key}")
        
        # –û–±'—î–¥–Ω—É—î–º–æ –≤–∫–ª–∞–¥–µ–Ω–Ω—è –∑ —Ä—ñ–∑–Ω–∏—Ö –¥–∂–µ—Ä–µ–ª
        all_attachments = []
        
        # –î–æ–¥–∞—î–º–æ –∫–µ—à–æ–≤–∞–Ω—ñ –≤–∫–ª–∞–¥–µ–Ω–Ω—è (–≤–∂–µ –æ—Ç—Ä–∏–º–∞–Ω—ñ —á–µ—Ä–µ–∑ get_cached_attachments)
        if attachments:
            logger.info(f"üì• Processing {len(attachments)} attachments from webhook/cache")
            all_attachments.extend(attachments)
        
        # –í–∏–¥–∞–ª—è—î–º–æ –¥—É–±–ª—ñ–∫–∞—Ç–∏ –∑–∞ ID —Ç–∞ —ñ–º'—è–º —Ñ–∞–π–ª—É
        unique_attachments = []
        seen_ids = set()
        seen_filenames = set()
        
        for att in all_attachments:
            att_id = att.get('id')
            filename = att.get('filename', '')
            
            # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª—ñ–∫–∞—Ç–∏ –∑–∞ ID
            if att_id and att_id in seen_ids:
                logger.debug(f"üîÑ Skipping duplicate attachment by ID: {filename} (ID: {att_id})")
                continue
                
            # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª—ñ–∫–∞—Ç–∏ –∑–∞ —ñ–º'—è–º —Ñ–∞–π–ª—É
            if filename and filename in seen_filenames:
                logger.debug(f"üîÑ Skipping duplicate attachment by filename: {filename}")
                continue
                
            # –î–æ–¥–∞—î–º–æ –¥–æ —É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö
            unique_attachments.append(att)
            if att_id:
                seen_ids.add(att_id)
            if filename:
                seen_filenames.add(filename)
        
        logger.info(f"‚úÖ After deduplication: {len(unique_attachments)} unique attachments")
        
        if not unique_attachments:
            logger.info("‚ÑπÔ∏è No attachments to process")
            return
        
        # –û–±—Ä–æ–±–ª—è—î–º–æ –∫–æ–∂–µ–Ω —Ñ–∞–π–ª –æ–∫—Ä–µ–º–æ
        success_count = 0
        error_count = 0
        
        for idx, attachment in enumerate(unique_attachments, 1):
            filename = attachment.get('filename', f'attachment_{idx}')
            att_id = attachment.get('id', 'unknown')
            
            logger.info(f"üìé Processing attachment {idx}/{len(unique_attachments)}: {filename} (ID: {att_id})")
            
            try:
                # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ callback —Ñ—É–Ω–∫—Ü—ñ—é –¥–ª—è –æ–±—Ä–æ–±–∫–∏
                result = await send_file_as_separate_message_callback({
                    'attachment': attachment,
                    'issue_key': issue_key,
                    'chat_id': chat_id
                })
                
                if result:
                    success_count += 1
                    logger.info(f"‚úÖ Successfully sent: {filename}")
                else:
                    error_count += 1
                    logger.error(f"‚ùå Failed to send: {filename}")
                    
            except Exception as e:
                error_count += 1
                logger.error(f"‚ùå Error processing attachment {filename}: {str(e)}", exc_info=True)
        
        logger.info(f"üèÅ Attachment processing complete: {success_count} successful, {error_count} failed")
        
    except Exception as e:
        logger.error(f"‚ùå Error in process_attachments_universal: {str(e)}", exc_info=True)

async def send_file_as_separate_message_callback(data: Dict[str, Any]) -> bool:
    """
    Callback —Ñ—É–Ω–∫—Ü—ñ—è –¥–ª—è –≤—ñ–¥–ø—Ä–∞–≤–∫–∏ –≤–∫–ª–∞–¥–µ–Ω—å —á–µ—Ä–µ–∑ attachment_processor.
    –ê–¥–∞–ø—Ç—É—î –¥–∞–Ω—ñ –¥–ª—è –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –∑ send_file_as_separate_message.
    
    Args:
        data: –°–ª–æ–≤–Ω–∏–∫ –∑ –∫–ª—é—á–∞–º–∏:
            - attachment: –¥–∞–Ω—ñ –≤–∫–ª–∞–¥–µ–Ω–Ω—è
            - issue_key: –∫–ª—é—á –∑–∞–¥–∞—á—ñ
            - chat_id: ID —á–∞—Ç—É
            
    Returns:
        bool: True —è–∫—â–æ —Ñ–∞–π–ª —É—Å–ø—ñ—à–Ω–æ –≤—ñ–¥–ø—Ä–∞–≤–ª–µ–Ω–æ
    """
    try:
        attachment = data.get('attachment', {})
        issue_key = data.get('issue_key', '')
        chat_id = data.get('chat_id', '')
        
        if not attachment or not issue_key or not chat_id:
            logger.error("Missing required data in send_file_as_separate_message_callback")
            return False
        
        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ —Ñ–∞–π–ª –∑ Jira
        filename = attachment.get('filename', 'unknown_file')
        
        logger.info(f"‚¨áÔ∏è Downloading file from Jira: {filename}")
        
        # –§–æ—Ä–º—É—î–º–æ URL –¥–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
        att_id = attachment.get('id', '')
        content_url = attachment.get('content', attachment.get('self', ''))
        urls = build_attachment_urls(JIRA_DOMAIN, att_id, filename, content_url)
        
        # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –Ω–∞—è–≤–Ω—É —Ñ—É–Ω–∫—Ü—ñ—é –¥–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
        file_content = await download_file_from_jira(urls)
        
        if not file_content:
            logger.error(f"Failed to download file content for {filename}")
            return False
        
        # –í–∏–∑–Ω–∞—á–∞—î–º–æ MIME —Ç–∏–ø
        mime_type = attachment.get('mimeType', attachment.get('contentType', _infer_mime_type(filename)))
        
        logger.info(f"üì§ File downloaded ({len(file_content)} bytes), sending to Telegram...")
        
        # –í—ñ–¥–ø—Ä–∞–≤–ª—è—î–º–æ —Ñ–∞–π–ª
        return await send_file_as_separate_message(
            chat_id=chat_id,
            filename=filename,
            file_content=file_content,
            mime_type=mime_type,
            issue_key=issue_key
        )
        
    except Exception as e:
        logger.error(f"Error in send_file_as_separate_message_callback: {str(e)}", exc_info=True)
        return False

async def send_telegram_text(chat_id: str, text: str) -> bool:
    """
    –î–æ–ø–æ–º—ñ–∂–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –¥–ª—è –Ω–∞–¥—Å–∏–ª–∞–Ω–Ω—è —Ç–µ–∫—Å—Ç–æ–≤–∏—Ö –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å –≤ Telegram.
    
    Args:
        chat_id: ID —á–∞—Ç—É –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ –≤ Telegram
        text: –¢–µ–∫—Å—Ç –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è (–º–æ–∂–µ –º—ñ—Å—Ç–∏—Ç–∏ HTML)
        
    Returns:
        bool: True, —è–∫—â–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è —É—Å–ø—ñ—à–Ω–æ –Ω–∞–¥—ñ—Å–ª–∞–Ω–æ
    """
    try:
        from config.config import TELEGRAM_BOT_TOKEN
        import requests
        
        tg_url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
        data = {
            'chat_id': chat_id,
            'text': text,
            'parse_mode': 'HTML'
        }
        
        response = requests.post(tg_url, json=data)
        
        if response.status_code == 200:
            logger.info(f"–ü–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è —É—Å–ø—ñ—à–Ω–æ –Ω–∞–¥—ñ—Å–ª–∞–Ω–æ")
            return True
        else:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ –Ω–∞–¥—Å–∏–ª–∞–Ω–Ω—è –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è: {response.status_code} - {response.text}")
            return False
            
    except Exception as e:
        logger.error(f"–ü–æ–º–∏–ª–∫–∞ –Ω–∞–¥—Å–∏–ª–∞–Ω–Ω—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –≤ Telegram: {str(e)}", exc_info=True)
        return False

def format_comment_text(text: str) -> str:
    """
    –§–æ—Ä–º–∞—Ç—É—î —Ç–µ–∫—Å—Ç –∫–æ–º–µ–Ω—Ç–∞—Ä—è –¥–ª—è Telegram, –æ–±—Ä–æ–±–ª—è—î —Ä–æ–∑–º—ñ—Ç–∫—É Jira.
    
    Args:
        text: –í–∏—Ö—ñ–¥–Ω–∏–π —Ç–µ–∫—Å—Ç –∫–æ–º–µ–Ω—Ç–∞—Ä—è
        
    Returns:
        str: –í—ñ–¥—Ñ–æ—Ä–º–∞—Ç–æ–≤–∞–Ω–∏–π —Ç–µ–∫—Å—Ç
    """
    if not text:
        return text
    
    # –û—á–∏—â–∞—î–º–æ Jira markup –¥–ª—è –∑–æ–±—Ä–∞–∂–µ–Ω—å
    # –§–æ—Ä–º–∞—Ç: !filename.ext|–ø–∞—Ä–∞–º–µ—Ç—Ä–∏!
    import re
    
    # –í–∏–¥–∞–ª—è—î–º–æ —Ä–æ–∑–º—ñ—Ç–∫—É –∑–æ–±—Ä–∞–∂–µ–Ω—å !image.jpg|width=719,height=1280,alt="image.jpg"!
    text = re.sub(r'!([^|]+\.[a-zA-Z0-9]+)(\|[^!]+)?!', '', text)
    
    # –í–∏–¥–∞–ª—è—î–º–æ –ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ —Ñ–∞–π–ª–∏ —É —Ñ–æ—Ä–º–∞—Ç—ñ [^filename.ext]
    text = re.sub(r'\[\^[^\]]+\]', '', text)
    
    # –í–∏–¥–∞–ª—è—î–º–æ –∑–∞–π–≤—ñ –ø—Ä–æ–±—ñ–ª–∏ —Ç–∞ –ø–æ—Ä–æ–∂–Ω—ñ —Ä—è–¥–∫–∏
    text = re.sub(r'\n\s*\n', '\n', text)  # –ó–∞–º—ñ–Ω—é—î–º–æ –∫—ñ–ª—å–∫–∞ –ø–æ—Ä–æ–∂–Ω—ñ—Ö —Ä—è–¥–∫—ñ–≤ –Ω–∞ –æ–¥–∏–Ω
    text = text.strip()
    
    # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ Jira bold –≤ HTML
    text = re.sub(r'\*([^*]+)\*', r'<b>\1</b>', text)
    
    # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ Jira italic –≤ HTML
    text = re.sub(r'_([^_]+)_', r'<i>\1</i>', text)
    
    return text

def is_duplicate_message(issue_key: str, message_text: str, has_attachment: bool = False) -> bool:
    """
    –ü–µ—Ä–µ–≤—ñ—Ä—è—î, —á–∏ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –≤–∂–µ –±—É–ª–æ –Ω–µ—â–æ–¥–∞–≤–Ω–æ –≤—ñ–¥–ø—Ä–∞–≤–ª–µ–Ω–æ –¥–ª—è —Ü—ñ—î—ó –∑–∞–¥–∞—á—ñ.
    –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –¥–ª—è –∑–∞–ø–æ–±—ñ–≥–∞–Ω–Ω—è –¥—É–±–ª—ñ–∫–∞—Ç—ñ–≤ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å.
    
    Args:
        issue_key: –ö–ª—é—á –∑–∞–¥–∞—á—ñ
        message_text: –¢–µ–∫—Å—Ç –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏
        has_attachment: True —è–∫—â–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –º—ñ—Å—Ç–∏—Ç—å –≤–∫–ª–∞–¥–µ–Ω–Ω—è
        
    Returns:
        bool: True —è–∫—â–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è —î –¥—É–±–ª—ñ–∫–∞—Ç–æ–º
    """
    # –Ø–∫—â–æ —î –≤–∫–ª–∞–¥–µ–Ω–Ω—è, –ø—Ä–æ–ø—É—Å–∫–∞—î–º–æ –ø–µ—Ä–µ–≤—ñ—Ä–∫—É –Ω–∞ –¥—É–±–ª—ñ–∫–∞—Ç–∏
    if has_attachment:
        return False
        
    if issue_key not in RECENT_MESSAGES_CACHE:
        return False
        
    normalized_text = " ".join(message_text.split()).lower()
    
    for cached_msg in RECENT_MESSAGES_CACHE[issue_key]:
        cached_text = " ".join(cached_msg["text"].split()).lower()
        if cached_text == normalized_text or cached_text in normalized_text or normalized_text in cached_text:
            return True
            
    return False

def add_message_to_cache(issue_key: str, message_text: str) -> None:
    """
    –î–æ–¥–∞—î –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –¥–æ –∫–µ—à—É –¥–ª—è –≤–∏—è–≤–ª–µ–Ω–Ω—è –¥—É–±–ª—ñ–∫–∞—Ç—ñ–≤.
    
    Args:
        issue_key: –ö–ª—é—á –∑–∞–¥–∞—á—ñ
        message_text: –¢–µ–∫—Å—Ç –≤—ñ–¥–ø—Ä–∞–≤–ª–µ–Ω–æ–≥–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è
    """
    RECENT_MESSAGES_CACHE[issue_key].append({
        "text": message_text,
        "timestamp": time.time()
    })

def cleanup_message_cache() -> None:
    """–í–∏–¥–∞–ª—è—î —Å—Ç–∞—Ä—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∑ –∫–µ—à—É."""
    current_time = time.time()
    
    for issue_key in list(RECENT_MESSAGES_CACHE.keys()):
        # –í—ñ–¥—Ñ—ñ–ª—å—Ç—Ä–æ–≤—É—î–º–æ —Ç—ñ–ª—å–∫–∏ –∞–∫—Ç—É–∞–ª—å–Ω—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è
        recent_messages = [
            msg for msg in RECENT_MESSAGES_CACHE[issue_key]
            if current_time - msg["timestamp"] < CACHE_TTL
        ]
        
        if recent_messages:
            RECENT_MESSAGES_CACHE[issue_key] = recent_messages
        else:
            del RECENT_MESSAGES_CACHE[issue_key]

def add_attachment_to_cache(issue_key: str, attachment: Dict[str, Any]) -> None:
    """
    –î–æ–¥–∞—î –≤–∫–ª–∞–¥–µ–Ω–Ω—è –¥–æ –∫–µ—à—É –¥–ª—è –ø–æ–¥–∞–ª—å—à–æ–≥–æ –∑–≤'—è–∑—É–≤–∞–Ω–Ω—è –∑ –∫–æ–º–µ–Ω—Ç–∞—Ä–µ–º.
    
    Args:
        issue_key: –ö–ª—é—á –∑–∞–¥–∞—á—ñ  
        attachment: –î–∞–Ω—ñ –≤–∫–ª–∞–¥–µ–Ω–Ω—è –∑ attachment_created –ø–æ–¥—ñ—ó
    """
    filename = attachment.get('filename', 'unknown')
    attachment_id = attachment.get('id', 'no-id')
    
    logger.info(f"üì¶ CACHING: {filename} for issue {issue_key} (ID: {attachment_id})")
    logger.info(f"üì¶ CACHE STATE BEFORE: {len(PENDING_ATTACHMENTS_CACHE)} issues, {sum(len(v) for v in PENDING_ATTACHMENTS_CACHE.values())} total attachments")
    
    cache_entry = {
        "attachment": attachment,
        "timestamp": time.time(),
        "filename": filename,
        "attachment_id": attachment_id
    }
    
    PENDING_ATTACHMENTS_CACHE[issue_key].append(cache_entry)
    
    logger.info(f"‚úÖ CACHED SUCCESSFULLY: Issue {issue_key} now has {len(PENDING_ATTACHMENTS_CACHE[issue_key])} cached attachments")
    logger.info(f"üì¶ CACHE STATE AFTER: {len(PENDING_ATTACHMENTS_CACHE)} issues, {sum(len(v) for v in PENDING_ATTACHMENTS_CACHE.values())} total attachments")
    
    # –î–µ—Ç–∞–ª—å–Ω–∏–π –≤–∏–≤—ñ–¥ –¥–ª—è –≤—ñ–¥–ª–∞–≥–æ–¥–∂–µ–Ω–Ω—è
    for cached_issue, cached_items in PENDING_ATTACHMENTS_CACHE.items():
        logger.info(f"   üìÅ Issue {cached_issue}: {len(cached_items)} attachments")
        for i, item in enumerate(cached_items):
            logger.info(f"      {i+1}. {item.get('filename', 'unknown')} (ID: {item.get('attachment_id', 'no-id')})")

def get_cached_attachments(issue_key: str) -> List[Dict[str, Any]]:
    """
    –û—Ç—Ä–∏–º—É—î –≤—Å—ñ –∑–∞–∫–µ—à–æ–≤–∞–Ω—ñ –≤–∫–ª–∞–¥–µ–Ω–Ω—è –¥–ª—è –∑–∞–¥–∞—á—ñ —ñ –æ—á–∏—â–∞—î –∫–µ—à.
    
    Args:
        issue_key: –ö–ª—é—á –∑–∞–¥–∞—á—ñ
        
    Returns:
        List[Dict]: –°–ø–∏—Å–æ–∫ –∑–∞–∫–µ—à–æ–≤–∞–Ω–∏—Ö –≤–∫–ª–∞–¥–µ–Ω—å
    """
    logger.info(f"üîç SEARCHING CACHE for issue {issue_key}")
    logger.info(f"üîç TOTAL CACHE STATE: {len(PENDING_ATTACHMENTS_CACHE)} issues cached")
    
    # –î–µ—Ç–∞–ª—å–Ω–∏–π –≤–∏–≤—ñ–¥ –ø–æ—Ç–æ—á–Ω–æ–≥–æ —Å—Ç–∞–Ω—É –∫–µ—à—É
    for cached_issue, cached_items in PENDING_ATTACHMENTS_CACHE.items():
        logger.info(f"   üìÅ Cached issue {cached_issue}: {len(cached_items)} attachments")
        for i, item in enumerate(cached_items):
            logger.info(f"      {i+1}. {item.get('filename', 'unknown')} (ID: {item.get('attachment_id', 'no-id')})")
    
    if issue_key not in PENDING_ATTACHMENTS_CACHE:
        logger.warning(f"‚ùå ISSUE KEY NOT FOUND IN CACHE: {issue_key}")
        logger.warning(f"‚ùå Available keys in cache: {list(PENDING_ATTACHMENTS_CACHE.keys())}")
        return []
    
    cached_attachments = PENDING_ATTACHMENTS_CACHE[issue_key]
    
    logger.info(f"‚úÖ FOUND {len(cached_attachments)} cached attachments for issue {issue_key}")
    for item in cached_attachments:
        logger.info(f"   üìé Found: {item['filename']} (ID: {item.get('attachment_id', 'no-id')})")
    
    # –û—á–∏—â–∞—î–º–æ –∫–µ—à –ø—ñ—Å–ª—è –æ—Ç—Ä–∏–º–∞–Ω–Ω—è
    del PENDING_ATTACHMENTS_CACHE[issue_key]
    
    # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ —Ç—ñ–ª—å–∫–∏ –¥–∞–Ω—ñ –≤–∫–ª–∞–¥–µ–Ω—å
    attachments = [item["attachment"] for item in cached_attachments]
    
    logger.info(f"üì§ RETURNING {len(attachments)} attachments to process")
    return attachments

def cleanup_attachment_cache() -> None:
    """–í–∏–¥–∞–ª—è—î —Å—Ç–∞—Ä—ñ –≤–∫–ª–∞–¥–µ–Ω–Ω—è –∑ –∫–µ—à—É."""
    current_time = time.time()
    
    # –û—á–∏—â–∞—î–º–æ –æ—Å–Ω–æ–≤–Ω–∏–π –∫–µ—à –∑–∞ issue_key
    for issue_key in list(PENDING_ATTACHMENTS_CACHE.keys()):
        # –í—ñ–¥—Ñ—ñ–ª—å—Ç—Ä–æ–≤—É—î–º–æ —Ç—ñ–ª—å–∫–∏ –∞–∫—Ç—É–∞–ª—å–Ω—ñ –≤–∫–ª–∞–¥–µ–Ω–Ω—è
        recent_attachments = [
            att for att in PENDING_ATTACHMENTS_CACHE[issue_key]
            if current_time - att["timestamp"] < ATTACHMENT_CACHE_TTL
        ]
        
        if recent_attachments:
            PENDING_ATTACHMENTS_CACHE[issue_key] = recent_attachments
        else:
            # –õ–æ–≥—É–≤–∞–Ω–Ω—è –¥–ª—è –≤—ñ–¥–ª–∞–≥–æ–¥–∂–µ–Ω–Ω—è
            old_count = len(PENDING_ATTACHMENTS_CACHE[issue_key])
            logger.warning(f"üóëÔ∏è Cleaning up {old_count} expired cached attachments for issue {issue_key}")
            del PENDING_ATTACHMENTS_CACHE[issue_key]
    
    # –û—á–∏—â–∞—î–º–æ –∫–µ—à –∑–∞ attachment_id
    expired_ids = []
    for att_id, cache_entry in ATTACHMENT_ID_CACHE.items():
        if current_time - cache_entry["timestamp"] > ATTACHMENT_ID_CACHE_TTL:
            expired_ids.append(att_id)
    
    for att_id in expired_ids:
        filename = ATTACHMENT_ID_CACHE[att_id].get("filename", "unknown")
        logger.warning(f"üóëÔ∏è Cleaning up expired attachment cache for ID {att_id}: {filename}")
        del ATTACHMENT_ID_CACHE[att_id]

def add_attachment_to_id_cache(attachment: Dict[str, Any]) -> None:
    """
    –î–æ–¥–∞—î –≤–∫–ª–∞–¥–µ–Ω–Ω—è –¥–æ –∫–µ—à—É –∑–∞ attachment_id (–∫–æ–ª–∏ issue_key –Ω–µ–≤—ñ–¥–æ–º–∏–π).
    
    Args:
        attachment: –î–∞–Ω—ñ –≤–∫–ª–∞–¥–µ–Ω–Ω—è –∑ attachment_created –ø–æ–¥—ñ—ó
    """
    attachment_id = attachment.get('id', '')
    filename = attachment.get('filename', 'unknown')
    
    if not attachment_id:
        logger.warning(f"Cannot cache attachment without ID: {filename}")
        return
    
    logger.info(f"üÜî Caching attachment by ID: {attachment_id} -> {filename}")
    
    ATTACHMENT_ID_CACHE[attachment_id] = {
        "attachment": attachment,
        "timestamp": time.time(),
        "filename": filename,
        "attachment_id": attachment_id
    }
    
    logger.info(f"üÜî ID-CACHE STATE: {len(ATTACHMENT_ID_CACHE)} attachments cached by ID")

def find_cached_attachments_by_patterns(issue_key: str, embedded_attachments: List[Dict[str, Any]], comment_timestamp: float, extend_time_window: bool = False) -> List[Dict[str, Any]]:
    """
    –ó–Ω–∞—Ö–æ–¥–∏—Ç—å –∑–∞–∫–µ—à–æ–≤–∞–Ω—ñ –≤–∫–ª–∞–¥–µ–Ω–Ω—è –∑–∞ —Ä—ñ–∑–Ω–∏–º–∏ –ø–∞—Ç–µ—Ä–Ω–∞–º–∏ –∑—ñ—Å—Ç–∞–≤–ª–µ–Ω–Ω—è.
    
    Args:
        issue_key: –ö–ª—é—á –∑–∞–¥–∞—á—ñ
        embedded_attachments: –í–∫–ª–∞–¥–µ–Ω–Ω—è –∑–Ω–∞–π–¥–µ–Ω—ñ –≤ —Ç–µ–∫—Å—Ç—ñ –∫–æ–º–µ–Ω—Ç–∞—Ä—è
        comment_timestamp: –ß–∞—Å —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –∫–æ–º–µ–Ω—Ç–∞—Ä—è
        extend_time_window: –†–æ–∑—à–∏—Ä–∏—Ç–∏ —á–∞—Å–æ–≤–µ –≤—ñ–∫–Ω–æ –¥–ª—è –ø–æ—à—É–∫—É –≤—Ç—Ä–∞—á–µ–Ω–∏—Ö —Ñ–∞–π–ª—ñ–≤
        
    Returns:
        List[Dict]: –°–ø–∏—Å–æ–∫ –∑–Ω–∞–π–¥–µ–Ω–∏—Ö –≤–∫–ª–∞–¥–µ–Ω—å
    """
    found_attachments = []
    
    logger.info(f"üîç SEARCHING FOR CACHED ATTACHMENTS using multiple strategies")
    logger.info(f"   - Issue key: {issue_key}")
    logger.info(f"   - Embedded attachments: {len(embedded_attachments)}")
    logger.info(f"   - Comment timestamp: {comment_timestamp}")
    logger.info(f"   - ID cache size: {len(ATTACHMENT_ID_CACHE)}")
    
    # –°—Ç—Ä–∞—Ç–µ–≥—ñ—è 1: –ü–æ—à—É–∫ –∑–∞ issue_key (—è–∫ —Ä–∞–Ω—ñ—à–µ)
    direct_cached = get_cached_attachments(issue_key)
    if direct_cached:
        logger.info(f"‚úÖ STRATEGY 1: Found {len(direct_cached)} attachments via issue_key cache")
        found_attachments.extend(direct_cached)
    else:
        logger.info(f"‚ùå STRATEGY 1: No attachments found via issue_key cache")
    
    # –°—Ç—Ä–∞—Ç–µ–≥—ñ—è 2: –ü–æ—à—É–∫ –∑–∞ —ñ–º–µ–Ω–∞–º–∏ —Ñ–∞–π–ª—ñ–≤ –∑ embedded attachments
    embedded_filenames = {att.get('filename', '') for att in embedded_attachments if att.get('filename')}
    if embedded_filenames:
        logger.info(f"üîç STRATEGY 2: Searching by embedded filenames: {embedded_filenames}")
        
        for att_id, cached_data in ATTACHMENT_ID_CACHE.items():
            cached_filename = cached_data.get('filename', '')
            
            # –ü–æ—Ä—ñ–≤–Ω—é—î–º–æ —ñ–º–µ–Ω–∞ —Ñ–∞–π–ª—ñ–≤ (–∑ —É—Ä–∞—Ö—É–≤–∞–Ω–Ω—è–º –º–æ–∂–ª–∏–≤–∏—Ö –≤—ñ–¥–º—ñ–Ω–Ω–æ—Å—Ç–µ–π)
            for embedded_filename in embedded_filenames:
                logger.info(f"   üîç Comparing: '{cached_filename}' vs '{embedded_filename}'")
                if files_match(cached_filename, embedded_filename):
                    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ –Ω–µ –¥–æ–¥–∞–Ω–æ –≤–∂–µ —Ü–µ–π attachment –∑–∞ ID
                    cached_attachment = cached_data['attachment']
                    attachment_id = cached_attachment.get('id', cached_attachment.get('attachment_id', att_id))
                    
                    is_duplicate = any(
                        att.get('id') == attachment_id or 
                        att.get('attachment_id') == attachment_id or
                        att.get('id') == att_id or
                        att.get('attachment_id') == att_id
                        for att in found_attachments
                    )
                    
                    if not is_duplicate:
                        logger.info(f"‚úÖ MATCHED by filename: {cached_filename} ‚âà {embedded_filename} (ID: {att_id})")
                        found_attachments.append(cached_attachment)
                    else:
                        logger.info(f"‚ö†Ô∏è SKIPPED duplicate: {cached_filename} ‚âà {embedded_filename} (ID: {att_id})")
                    break
                else:
                    logger.info(f"‚ùå NO MATCH: '{cached_filename}' ‚â† '{embedded_filename}'")
    
    # –°—Ç—Ä–∞—Ç–µ–≥—ñ—è 3: –ü–æ—à—É–∫ –∑–∞ —á–∞—Å–æ–≤–∏–º–∏ –º—ñ—Ç–∫–∞–º–∏ (—Ä–æ–∑—à–∏—Ä–µ–Ω–µ –≤—ñ–∫–Ω–æ –¥–ª—è recovery)
    if extend_time_window:
        time_window = 600  # 10 —Ö–≤–∏–ª–∏–Ω –¥–ª—è —Ä–æ–∑—à–∏—Ä–µ–Ω–æ–≥–æ –ø–æ—à—É–∫—É –≤—Ç—Ä–∞—á–µ–Ω–∏—Ö —Ñ–∞–π–ª—ñ–≤
        logger.info(f"üîÑ EXTENDED STRATEGY 3: Searching by timestamp within {time_window}s of comment (RECOVERY MODE)")
    else:
        time_window = 180  # —Å–µ–∫—É–Ω–¥ - –∑–±—ñ–ª—å—à–µ–Ω–æ –∑ 30 –¥–æ 180 –¥–ª—è –æ–±—Ä–æ–±–∫–∏ –ø–∞–∫–µ—Ç–Ω–∏—Ö –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—å
        logger.info(f"üîç STRATEGY 3: Searching by timestamp within {time_window}s of comment")
    
    for att_id, cached_data in ATTACHMENT_ID_CACHE.items():
        cached_timestamp = cached_data.get('timestamp', 0)
        time_diff = abs(comment_timestamp - cached_timestamp)
        filename = cached_data.get('filename', 'unknown')
        
        logger.info(f"   üìÖ Checking: {filename} (ID: {att_id}, time_diff: {time_diff:.1f}s)")
        
        if time_diff <= time_window:
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ –Ω–µ –¥–æ–¥–∞–Ω–æ –≤–∂–µ —Ü–µ–π attachment
            cached_attachment = cached_data['attachment']
            attachment_id = cached_attachment.get('id', cached_attachment.get('attachment_id', att_id))
            
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –¥—É–±–ª—ñ–∫–∞—Ç–∏ –∑–∞ —Ä—ñ–∑–Ω–∏–º–∏ –º–æ–∂–ª–∏–≤–∏–º–∏ ID
            is_duplicate = any(
                att.get('id') == attachment_id or 
                att.get('attachment_id') == attachment_id or
                att.get('id') == att_id or
                att.get('attachment_id') == att_id
                for att in found_attachments
            )
            
            if not is_duplicate:
                logger.info(f"‚úÖ MATCHED by timestamp: {filename} (time_diff: {time_diff:.1f}s)")
                found_attachments.append(cached_attachment)
            else:
                logger.info(f"‚ö†Ô∏è SKIPPED duplicate: {filename} (time_diff: {time_diff:.1f}s)")
        else:
            logger.info(f"‚è∞ TOO OLD: {filename} (time_diff: {time_diff:.1f}s > {time_window}s)")
    
    logger.info(f"üéØ TOTAL FOUND via all strategies: {len(found_attachments)} attachments")
    return found_attachments

def files_match(filename1: str, filename2: str) -> bool:
    """
    –ü–µ—Ä–µ–≤—ñ—Ä—è—î, —á–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—é—Ç—å –¥–≤–∞ —ñ–º–µ–Ω—ñ —Ñ–∞–π–ª—ñ–≤ (–∑ —É—Ä–∞—Ö—É–≤–∞–Ω–Ω—è–º –º–æ–∂–ª–∏–≤–∏—Ö –≤—ñ–¥–º—ñ–Ω–Ω–æ—Å—Ç–µ–π).
    
    Args:
        filename1: –ü–µ—Ä—à–µ —ñ–º'—è —Ñ–∞–π–ª—É
        filename2: –î—Ä—É–≥–µ —ñ–º'—è —Ñ–∞–π–ª—É
        
    Returns:
        bool: True —è–∫—â–æ —Ñ–∞–π–ª–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—é—Ç—å
    """
    if not filename1 or not filename2:
        return False
    
    # –ü—Ä—è–º–µ —Å–ø—ñ–≤–ø–∞–¥—ñ–Ω–Ω—è
    if filename1 == filename2:
        return True
    
    # –°–ø—ñ–≤–ø–∞–¥—ñ–Ω–Ω—è –±–µ–∑ —É—Ä–∞—Ö—É–≤–∞–Ω–Ω—è —Ä–µ–≥—ñ—Å—Ç—Ä—É
    if filename1.lower() == filename2.lower():
        return True
    
    # –°–ø—ñ–≤–ø–∞–¥—ñ–Ω–Ω—è –æ—Å–Ω–æ–≤–Ω–æ—ó —á–∞—Å—Ç–∏–Ω–∏ —ñ–º–µ–Ω—ñ (–±–µ–∑ GUID —Ç–∞ —ñ–Ω—à–∏—Ö —Å—É—Ñ—ñ–∫—Å—ñ–≤)
    import re
    
    # –í–∏–¥–∞–ª—è—î–º–æ GUID-–ø–æ–¥—ñ–±–Ω—ñ —Å—É—Ñ—ñ–∫—Å–∏
    clean1 = re.sub(r'\s*\([a-f0-9-]{36}\)', '', filename1)
    clean2 = re.sub(r'\s*\([a-f0-9-]{36}\)', '', filename2)
    
    if clean1.lower() == clean2.lower():
        return True
    
    # –°–ø—ñ–≤–ø–∞–¥—ñ–Ω–Ω—è –±–∞–∑–æ–≤–æ–≥–æ —ñ–º–µ–Ω—ñ —Ñ–∞–π–ª—É (–±–µ–∑ —Ä–æ–∑—à–∏—Ä–µ–Ω–Ω—è)
    base1 = filename1.rsplit('.', 1)[0].lower()
    base2 = filename2.rsplit('.', 1)[0].lower()
    
    if base1 == base2:
        return True
    
    return False

# –§—É–Ω–∫—Ü—ñ—è –¥–ª—è —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—ó –∑ –æ—Å–Ω–æ–≤–Ω–∏–º –∑–∞—Å—Ç–æ—Å—É–Ω–∫–æ–º
async def setup_webhook_server(app, host: str, port: int, ssl_context: Optional[Any] = None):
    """
    –ù–∞–ª–∞—à—Ç–æ–≤—É—î —ñ –∑–∞–ø—É—Å–∫–∞—î –≤–µ–±-—Å–µ—Ä–≤–µ—Ä –¥–ª—è –æ–±—Ä–æ–±–∫–∏ –≤–µ–±—Ö—É–∫—ñ–≤.
    
    Args:
        app: –û–±'—î–∫—Ç –∑–∞—Å—Ç–æ—Å—É–Ω–∫—É Telegram
        host: –•–æ—Å—Ç –¥–ª—è –∑–∞–ø—É—Å–∫—É –≤–µ–±-—Å–µ—Ä–≤–µ—Ä–∞
        port: –ü–æ—Ä—Ç –¥–ª—è –∑–∞–ø—É—Å–∫—É –≤–µ–±-—Å–µ—Ä–≤–µ—Ä–∞
        ssl_context: SSL-–∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –∑–∞—Ö–∏—â–µ–Ω–æ–≥–æ –∑'—î–¥–Ω–∞–Ω–Ω—è
    """
    # –°—Ç–≤–æ—Ä—é—î–º–æ –≤–µ–±-–∑–∞—Å—Ç–æ—Å—É–Ω–æ–∫ aiohttp –∑ –±—ñ–ª—å—à–∏–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∏–º —Ä–æ–∑–º—ñ—Ä–æ–º —Ç—ñ–ª–∞ –∑–∞–ø–∏—Ç—É
    web_app = web.Application(
        client_max_size=50 * 1024 * 1024,  # 50MB limit
        middlewares=[security_middleware]  # –î–æ–¥–∞—î–º–æ security middleware
    )
    
    # –ù–∞–ª–∞—à—Ç–æ–≤—É—î–º–æ –º–∞—Ä—à—Ä—É—Ç–∏
    web_app.router.add_post('/rest/webhooks/webhook1', handle_webhook)
    
    # –ù–∞–ª–∞—à—Ç—É—î–º–æ –¥–æ–¥–∞—Ç–∫–æ–≤–∏–π –º–∞—Ä—à—Ä—É—Ç –¥–ª—è –ø—Ä–æ—Å—Ç–æ—ó –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ —Ä–æ–±–æ—Ç–∏ –≤–µ–±—Ö—É–∫—É
    async def ping(request):
        return web.json_response({
            "status": "ok",
            "message": "Webhook server is running",
            "max_size": "50MB"
        })
        
    web_app.router.add_get('/rest/webhooks/ping', ping)
    
    # –î–æ–¥–∞—î–º–æ endpoint –¥–ª—è –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥—É security —Å—Ç–∞—Ç—É—Å—É
    async def security_status(request):
        """Endpoint –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ security —Å—Ç–∞—Ç—É—Å—É (rate limiting, blacklist)."""
        current_time = time.time()
        
        # –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ blacklist
        blacklisted_ips = []
        for ip, until_time in RATE_LIMIT_BLACKLIST.items():
            if until_time > current_time:
                remaining = int(until_time - current_time)
                blacklisted_ips.append({
                    "ip": ip,
                    "remaining_seconds": remaining
                })
        
        # –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ rate limiting
        active_ips = {}
        for ip, requests in RATE_LIMIT_TRACKER.items():
            # –í–∏–¥–∞–ª—è—î–º–æ —Å—Ç–∞—Ä—ñ –∑–∞–ø–∏—Ç–∏
            while requests and requests[0] < current_time - RATE_LIMIT_WINDOW:
                requests.popleft()
            if requests:
                active_ips[ip] = len(requests)
        
        return web.json_response({
            "status": "ok",
            "security": {
                "rate_limit": {
                    "window_seconds": RATE_LIMIT_WINDOW,
                    "max_requests": RATE_LIMIT_MAX_REQUESTS,
                    "blacklist_duration": RATE_LIMIT_BLACKLIST_DURATION,
                    "active_ips": active_ips,
                    "blacklisted_ips": blacklisted_ips
                },
                "ip_whitelist": {
                    "enabled": True,
                    "whitelist_size": len(IP_WHITELIST)
                }
            }
        })
    
    web_app.router.add_get('/rest/webhooks/security-status', security_status)
    
    # –ó–∞–ø—É—Å–∫–∞—î–º–æ –≤–µ–±-—Å–µ—Ä–≤–µ—Ä
    runner = web.AppRunner(web_app)
    await runner.setup()
    
    # –°—Ç–≤–æ—Ä—é—î–º–æ —Å–∞–π—Ç —ñ –∑–∞–ø—É—Å–∫–∞—î–º–æ –π–æ–≥–æ
    # –ó–∞–≤–∂–¥–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ HTTP, –æ—Å–∫—ñ–ª—å–∫–∏ Nginx –æ–±—Ä–æ–±–ª—è—î SSL
    site = web.TCPSite(runner, host, port)
    logger.info(f"–ó–∞–ø—É—Å–∫–∞—î–º–æ –≤–µ–±—Ö—É–∫-—Å–µ—Ä–≤–µ—Ä HTTP –Ω–∞ {host}:{port} (SSL –æ–±—Ä–æ–±–ª—è—î Nginx)")
    
    await site.start()
    logger.info(f"–°–µ—Ä–≤–µ—Ä –≤–µ–±—Ö—É–∫—ñ–≤ –∑–∞–ø—É—â–µ–Ω–æ –Ω–∞ {host}:{port} –∑ –ª—ñ–º—ñ—Ç–æ–º —Ä–æ–∑–º—ñ—Ä—É –∑–∞–ø–∏—Ç—É 50MB")
    
    return runner

async def send_attachment_to_telegram(attachment_data: dict) -> bool:
    """
    Callback function for sending attachments to Telegram.
    Used by the attachment processor.
    
    Args:
        attachment_data: Dict with keys:
            - chat_id: str
            - file_name: str
            - file_bytes: bytes
            - mime_type: str
            - issue_key: str
            
    Returns:
        bool: True if message was sent successfully
    """
    try:
        chat_id = attachment_data.get('chat_id', '')
        filename = attachment_data.get('file_name', '')
        file_bytes = attachment_data.get('file_bytes', b'')
        mime_type = attachment_data.get('mime_type', '')
        issue_key = attachment_data.get('issue_key', '')
        file_size = len(file_bytes) if file_bytes else 0
        
        if not file_bytes:
            logger.error("Empty file content provided to send_attachment_to_telegram")
            return False
        
        # Size limits based on Telegram API constraints    
        size_limit = 50 * 1024 * 1024  # 50MB default
        if mime_type.startswith('image/'):
            size_limit = 10 * 1024 * 1024  # 10MB for photos
            
        # Prepare message text (simplified without tech support header)
        icon = "üñºÔ∏è" if mime_type.startswith('image/') else "üìé"
        file_size_mb = file_size / (1024 * 1024)
        file_info = f"{filename} ({file_size_mb:.1f} MB)"
        message = f"{icon} <b>{file_info}</b>"
        
        # Check file size limit
        if file_size > size_limit:
            warning_msg = (f"{message}\n\n‚ö†Ô∏è <i>–§–∞–π–ª –∑–∞–≤–µ–ª–∏–∫–∏–π –¥–ª—è –Ω–∞–¥—Å–∏–ª–∞–Ω–Ω—è –≤ Telegram "
                         f"(–æ–±–º–µ–∂–µ–Ω–Ω—è {size_limit/(1024*1024):.0f}MB). "
                         f"–ë—É–¥—å –ª–∞—Å–∫–∞, –∑–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ –π–æ–≥–æ –±–µ–∑–ø–æ—Å–µ—Ä–µ–¥–Ω—å–æ –∑ Jira.</i>")
            return await send_telegram_message(chat_id, warning_msg)
        
        # Send using the existing send_telegram_message function
        return await send_telegram_message(chat_id, message, (filename, file_bytes, mime_type))
    
    except Exception as e:
        logger.error(f"Error in send_attachment_to_telegram: {str(e)}", exc_info=True)
        return False

async def process_attachments(attachments: List[Dict[str, Any]], issue_key: str, chat_id: str) -> None:
    """
    Process and send attachment files from Jira to Telegram.
    This function delegates to the new attachment_processor utilities.
    
    Args:
        attachments: List of attachment objects from Jira
        issue_key: The issue key (e.g., 'SD-40461')
        chat_id: Telegram chat ID to send files to
    """
    try:
        if not attachments:
            logger.info("No attachments to process")
            return
            
        logger.info(f"Processing {len(attachments)} attachments for issue {issue_key}")
        
        # Add chat_id to each attachment for use by the processor
        for att in attachments:
            att['chat_id'] = chat_id
            
        # Use our new utilities to process attachments
        success, errors = await process_attachments_for_issue(
            JIRA_DOMAIN,
            attachments,
            issue_key,
            send_attachment_to_telegram
        )
        
        logger.info(f"Completed processing attachments: {success} successful, {errors} failed")
        
    except Exception as e:
        logger.error(f"Error in process_attachments: {str(e)}", exc_info=True)

def extract_embedded_attachments(text: str) -> List[dict]:
    """
    Extracts information about embedded attachments from Jira comment text.
    Processes syntax like !filename.ext|data-attachment-id=123! and other variations.
    
    Args:
        text: The comment text to analyze
        
    Returns:
        List[dict]: List of dictionaries with attachment info
    """
    if not text:
        return []
        
    attachments = []
    
    # Extract embedded files using regex
    embedded_files = re.finditer(r'!([^|!]+)(?:\|([^!]+))?!', text)
    
    for file_match in embedded_files:
        # Get file name and parameters
        filename = file_match.group(1).split('/')[-1]
        clean_filename = urllib.parse.unquote(filename)
        
        # Initialize attachment info
        attachment_info = {
            'filename': clean_filename,
            'embedded': True
        }
        
        # Extract attachment ID from parameters if any
        attachment_id = None
        if file_match.group(2):  # If there are parameters
            params = file_match.group(2).strip('|').split(',')
            for param in params:
                if '=' in param:
                    key, value = param.split('=', 1)
                    value = value.strip('"')
                    
                    if key == 'data-attachment-id':
                        attachment_id = value
                        attachment_info['id'] = value
                    elif key == 'alt':
                        if value:
                            attachment_info['alt'] = value
        
        # Form the URL for downloading
        if attachment_id:
            jira_url = f"{JIRA_DOMAIN}/secure/attachment/{attachment_id}/{urllib.parse.quote(clean_filename)}"
        else:
            jira_url = f"{JIRA_DOMAIN}/secure/attachment/{urllib.parse.quote(clean_filename)}"
            
        if not jira_url.startswith(('http://', 'https://')):
            jira_url = f"https://{jira_url}"
            
        attachment_info['content'] = jira_url
        
        # Infer MIME type from extension
        attachment_info['mimeType'] = _infer_mime_type(clean_filename)
        
        attachments.append(attachment_info)
    
    return attachments

def _infer_mime_type(filename: str) -> str:
    """Helper function to infer MIME type from filename extension"""
    ext = filename.lower().split('.')[-1] if '.' in filename else ''
    
    # Images
    if ext in ['jpg', 'jpeg']:
        return 'image/jpeg'
    elif ext == 'png':
        return 'image/png'
    elif ext == 'gif':
        return 'image/gif'
    elif ext == 'bmp':
        return 'image/bmp'
    elif ext == 'webp':
        return 'image/webp'
    elif ext == 'svg':
        return 'image/svg+xml'
    elif ext == 'ico':
        return 'image/x-icon'
    
    # Videos
    elif ext == 'mp4':
        return 'video/mp4'
    elif ext == 'avi':
        return 'video/x-msvideo'
    elif ext == 'mov':
        return 'video/quicktime'
    elif ext == 'wmv':
        return 'video/x-ms-wmv'
    elif ext == 'flv':
        return 'video/x-flv'
    elif ext == 'mkv':
        return 'video/x-matroska'
    
    # Audio
    elif ext == 'mp3':
        return 'audio/mpeg'
    elif ext == 'wav':
        return 'audio/wav'
    elif ext == 'flac':
        return 'audio/flac'
    elif ext == 'aac':
        return 'audio/aac'
    elif ext == 'ogg':
        return 'audio/ogg'
    
    # Documents
    elif ext == 'pdf':
        return 'application/pdf'
    elif ext == 'doc':
        return 'application/msword'
    elif ext == 'docx':
        return 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'
    elif ext == 'xls':
        return 'application/vnd.ms-excel'
    elif ext == 'xlsx':
        return 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
    elif ext == 'ppt':
        return 'application/vnd.ms-powerpoint'
    elif ext == 'pptx':
        return 'application/vnd.openxmlformats-officedocument.presentationml.presentation'
    elif ext == 'odt':
        return 'application/vnd.oasis.opendocument.text'
    elif ext == 'ods':
        return 'application/vnd.oasis.opendocument.spreadsheet'
    elif ext == 'odp':
        return 'application/vnd.oasis.opendocument.presentation'
    elif ext == 'rtf':
        return 'application/rtf'
    
    # Archives
    elif ext == 'zip':
        return 'application/zip'
    elif ext == 'rar':
        return 'application/x-rar-compressed'
    elif ext == '7z':
        return 'application/x-7z-compressed'
    elif ext == 'tar':
        return 'application/x-tar'
    elif ext == 'gz':
        return 'application/gzip'
    elif ext == 'bz2':
        return 'application/x-bzip2'
    
    # Text files
    elif ext == 'txt':
        return 'text/plain'
    elif ext == 'csv':
        return 'text/csv'
    elif ext == 'json':
        return 'application/json'
    elif ext == 'xml':
        return 'application/xml'
    elif ext == 'html':
        return 'text/html'
    elif ext == 'css':
        return 'text/css'
    elif ext == 'js':
        return 'application/javascript'
    
    # Programming files
    elif ext == 'py':
        return 'text/x-python'
    elif ext == 'java':
        return 'text/x-java-source'
    elif ext == 'cpp':
        return 'text/x-c++src'
    elif ext == 'c':
        return 'text/x-csrc'
    elif ext == 'php':
        return 'text/x-php'
    elif ext == 'sql':
        return 'text/x-sql'
    
    # Default for unknown types
    else:
        return 'application/octet-stream'


if __name__ == "__main__":
    try:
        logger.info("üöÄ Starting Jira Webhook Handler...")
        logger.info(f"üì° Server will run on http://0.0.0.0:8080")
        
        app = web.Application()
        app.router.add_post('/webhook', handle_webhook)
        
        # Add a simple health check endpoint
        async def health_check(request):
            return web.json_response({"status": "ok", "service": "jira-webhook-handler"})
        
        app.router.add_get('/health', health_check)
        
        # Start the server
        web.run_app(app, host='0.0.0.0', port=8080)
        
    except Exception as e:
        logger.error(f"‚ùå Failed to start webhook server: {e}")
        import traceback
        logger.error(traceback.format_exc())
